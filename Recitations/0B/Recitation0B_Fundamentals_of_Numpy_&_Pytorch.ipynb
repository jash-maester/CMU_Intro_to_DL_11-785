{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recitation0B_Fundamentals_of_Numpy_&_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0IXcXq7pEE"
      },
      "source": [
        "#Recitation 0B: Fundamentals of Numpy & PyTorch\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5enyRdM5to8"
      },
      "source": [
        "## **Contents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJnUIWYIgWLJ"
      },
      "source": [
        "1. Introduction\r\n",
        "    1. Setting Up Numpy & Pytorch - install & import\r\n",
        "2. Initializations\r\n",
        "    1. Numpy Arrays & Tensors\r\n",
        "    2. Interconversions\r\n",
        "3. Accessing and modifying data\r\n",
        "  1. Indexing\r\n",
        "  2. Slicing\r\n",
        "4. Pivoting Data\r\n",
        "  1. Flatten\r\n",
        "  1. Squeeze\r\n",
        "  1. Reshape\r\n",
        "  1. Transpose\r\n",
        "5. Combining Data\r\n",
        "  1. Cat\r\n",
        "  2. Stack\r\n",
        "  3. Repeat\r\n",
        "  4. Padding\r\n",
        "6. Mathematical operations\r\n",
        "  1. Point-wise/element-wise operations\r\n",
        "  1. Redution operations\r\n",
        "  1. Comparison operations\r\n",
        "  1. Vector/Matrix operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z6Qy7hH2iEr"
      },
      "source": [
        "## **1. Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY4qmPdNbRm9"
      },
      "source": [
        " If you're wondering why it's good to know both libraries, check this out: https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bnYRky0hIMm"
      },
      "source": [
        "### 1a. Setting Up Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh6NixenhdBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31f211e-f8d8-4afd-febd-6e60b93f1435"
      },
      "source": [
        "#You can set install NumPy by using the following command\r\n",
        "!pip install numpy\r\n",
        "# If you want to check the version of numpy you are using or if you want to conifrm if it is installed in your system, you can use the following command:\r\n",
        "!pip show numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Name: numpy\n",
            "Version: 1.19.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: yellowbrick, xgboost, xarray, wordcloud, umap-learn, torchvision, torchtext, torch, tifffile, thinc, Theano, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-datasets, tensorboard, tables, statsmodels, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, resampy, qdldl, PyWavelets, python-louvain, pystan, pysndfile, pymc3, pyemd, pyarrow, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, np-utils, nibabel, moviepy, mlxtend, mizani, missingno, matplotlib, matplotlib-venn, lucid, lightgbm, librosa, knnimpute, Keras, Keras-Preprocessing, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, holoviews, h5py, gym, gensim, folium, fix-yahoo-finance, fbprophet, fastprogress, fastdtw, fastai, fancyimpute, fa2, ecos, daft, cvxpy, cufflinks, cmdstanpy, chainer, Bottleneck, bokeh, blis, autograd, atari-py, astropy, altair, albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAGQtfHnhmbp"
      },
      "source": [
        "# Run this to ensure that you have properly installed Numpy on your machine and are ready to go!\r\n",
        "import numpy as np\r\n",
        "np.random.seed(0) #this is to ensure that every time the notebook is run, the same \"random\" numbers are generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfigfnBRhuow"
      },
      "source": [
        "### 1b. Setting Up Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va4yGGNyiWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88d66e7-0cd2-489f-a3a7-ca237bedb79c"
      },
      "source": [
        "#You can set install Pytorch by using the following command\r\n",
        "!pip install torch\r\n",
        "# If you want to check the version of pytorch you are using or if you want to conifrm if it is installed in your system, you can use the following command:\r\n",
        "!pip show torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Name: torch\n",
            "Version: 1.7.0+cu101\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: dataclasses, typing-extensions, future, numpy\n",
            "Required-by: torchvision, torchtext, fastai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGEMbH34Lxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774e3e31-84fb-4da9-cdee-c7869a7036b2"
      },
      "source": [
        "# Run this to ensure that you have properly installed Pytorch on your machine and are ready to go!\n",
        "import torch\n",
        "torch.manual_seed(0) #this is to ensure that every time the notebook is run, the same \"random\" numbers are generated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcb755a2b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2pbKR6Ui1Av"
      },
      "source": [
        "## **2. Initializations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqmJv0L7j8Nd"
      },
      "source": [
        "### 2a. NumPy Arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScW8QJGaj2bl"
      },
      "source": [
        "\r\n",
        "\r\n",
        "An array is a data structure that stores values of same data type. In Python, this is the main difference between arrays and lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6XrMQL6kH1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2501f8fd-615f-40fd-c715-178df7b5dc88"
      },
      "source": [
        "# Initializes a numpy array of zeroes, with size (3,4)\r\n",
        "new_array1 = np.zeros((3, 4))\r\n",
        "print(\"First array is:\\n\", new_array1, \"\\n\")\r\n",
        "\r\n",
        "# Initializes a numpy array of ones, with size (3,4)\r\n",
        "new_array2 = np.ones((3, 4))\r\n",
        "print(\"Second array is:\\n\", new_array2, \"\\n\")\r\n",
        "\r\n",
        "# Initializes a numpy array of zeroes, with size (3,4,5)\r\n",
        "new_array3 = np.zeros((3, 4, 5))\r\n",
        "print(\"Third array is:\\n\", new_array3, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First array is:\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]] \n",
            "\n",
            "Second array is:\n",
            " [[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]] \n",
            "\n",
            "Third array is:\n",
            " [[[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX0z1tHKkni0"
      },
      "source": [
        "NumPy arrays can also be initialized with random uniform distribution and integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmr-nOy5kwbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84736f0-886f-45e9-ba7e-9aef2bf83bdc"
      },
      "source": [
        "# Initializes a random numpy array with uniformly distributed numbers from the standard normal distribution\r\n",
        "new_array4 = np.random.randn(3, 4) \r\n",
        "print(\"Fourth array is:\\n\", new_array4, \"\\n\")\r\n",
        "\r\n",
        "# Initializes a random numpy array with randomly distributed integers in the range [0, 3)\r\n",
        "new_array5 = np.random.randint(3, size = (4, 5)) \r\n",
        "print(\"Fifth array is:\\n\", new_array5, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fourth array is:\n",
            " [[ 1.76405235  0.40015721  0.97873798  2.2408932 ]\n",
            " [ 1.86755799 -0.97727788  0.95008842 -0.15135721]\n",
            " [-0.10321885  0.4105985   0.14404357  1.45427351]] \n",
            "\n",
            "Fifth array is:\n",
            " [[0 1 1 1 1]\n",
            " [0 1 0 0 1]\n",
            " [2 0 2 0 1]\n",
            " [1 2 0 1 1]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSPxTEdymBNM"
      },
      "source": [
        "### 2b. Torch Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ZSbHE2mt6c"
      },
      "source": [
        "A torch.Tensor is a multi-dimensional matrix containing elements of a single data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqgicxmu2Z5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3061b1d4-dbe6-49aa-cabe-20e31dd81d41"
      },
      "source": [
        "# Initializes a torch tensor of zeroes, with size (5,3)\n",
        "new_tensor1 = torch.zeros(size=(5,3))\n",
        "print(\"First tensor is:\\n\", new_tensor1, \"\\n\")\n",
        "\n",
        "# Initializes a torch tensor of ones, with size (5,3)\n",
        "new_tensor2 = torch.ones(size=(5,3))\n",
        "print(\"Second tensor is:\\n\", new_tensor2, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First tensor is:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "Second tensor is:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRs0kUUCrsmj"
      },
      "source": [
        "Tensors can also be initialized in multiple ways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyhw0pvsml1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecdadf7-75e6-4963-ef33-6ec3a1d0fe4f"
      },
      "source": [
        "# Returns a 2-D tensor with ones on the diagonal and zeros elsewhere\r\n",
        "new_tensor3 = torch.eye(3)\r\n",
        "print(\"Third tensor is:\\n\", new_tensor3, \"\\n\")\r\n",
        "\r\n",
        "# Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)\r\n",
        "new_tensor4 = torch.rand(size=(3,4))\r\n",
        "print(\"Fourth tensor is:\\n\", new_tensor4, \"\\n\")\r\n",
        "\r\n",
        "# Returns a 1-D tensor with values from the interval [start, end) taken with common difference step beginning from start\r\n",
        "new_tensor5 = torch.arange(start=-3, end=9, step=2)\r\n",
        "print(\"Fifth tensor is:\\n\", new_tensor5, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Third tensor is:\n",
            " tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]]) \n",
            "\n",
            "Fourth tensor is:\n",
            " tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
            "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
            "        [0.4556, 0.6323, 0.3489, 0.4017]]) \n",
            "\n",
            "Fifth tensor is:\n",
            " tensor([-3, -1,  1,  3,  5,  7]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y8NGhUJtjdF"
      },
      "source": [
        "### 2c. Interconversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSge8E5dZ1D-"
      },
      "source": [
        "List --> Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRK9AjhaGpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40c41b7-8fad-4cab-9b50-c22580b73f4c"
      },
      "source": [
        "#Converting a list to numpy array\r\n",
        "\r\n",
        "list1 = [1, 2, 3, 4, 5]\r\n",
        "print(list1, type(list1), \"\\n\")\r\n",
        "\r\n",
        "list_toarray = np.array(list1)\r\n",
        "print(list_toarray, type(list_toarray))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5] <class 'list'> \n",
            "\n",
            "[1 2 3 4 5] <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwLYgsfjZ7Oo"
      },
      "source": [
        "List --> Torch Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wsmRIHSaZ96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46353b7-b4e7-4a9a-d633-d9d37bcabb71"
      },
      "source": [
        "#Converting a list to torch tensor\r\n",
        "\r\n",
        "list2 = [6, 7, 8, 9, 10]\r\n",
        "print(list2, type(list2), \"\\n\")\r\n",
        "\r\n",
        "list_totensor = torch.tensor(list2)\r\n",
        "print(list_totensor, type(list_totensor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6, 7, 8, 9, 10] <class 'list'> \n",
            "\n",
            "tensor([ 6,  7,  8,  9, 10]) <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genwSb5XZ-Wg"
      },
      "source": [
        "Numpy Array --> Torch Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDQvfUfc4YFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdffc864-4c54-4292-d288-d7a3cb38c1fe"
      },
      "source": [
        "old_nparray = np.array([1,2,3,4])\n",
        "print(old_nparray, type(old_nparray), \"\\n\")\n",
        "\n",
        "# Convert numpy array to tensor \n",
        "\n",
        "new_tensor = torch.from_numpy(old_nparray)\n",
        "print(new_tensor, type(new_tensor), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4] <class 'numpy.ndarray'> \n",
            "\n",
            "tensor([1, 2, 3, 4]) <class 'torch.Tensor'> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUgJTgR2pRq6"
      },
      "source": [
        "Torch Tensor --> Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3_h_FtfiYIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd703f8d-8dba-4930-9b71-c594a9692f6e"
      },
      "source": [
        "old_tensor = torch.tensor([5,6,7,8])\r\n",
        "print(old_tensor, type(old_tensor), \"\\n\")\r\n",
        "\r\n",
        "# Convert tensor to numpy array\r\n",
        "\r\n",
        "new_nparray = old_tensor.detach().numpy()\r\n",
        "print(new_nparray, type(new_nparray), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5, 6, 7, 8]) <class 'torch.Tensor'> \n",
            "\n",
            "[5 6 7 8] <class 'numpy.ndarray'> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgo3dkKT6lky"
      },
      "source": [
        "## **3. Accessing & Modifying Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oefhY7K-t4bb"
      },
      "source": [
        "**NOTE:** Values can easily be modified by using the accessing method to select the desired section of the array/tensor to be modified\r\n",
        "\r\n",
        "\r\n",
        "*   Indexing is using the location of an element in an array/tensor to extract it.\r\n",
        "*   Slicing is used to obtain/extract a subset of elements in an array/tensor.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQtWqB-xvBxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abb5913-abb7-4018-be38-1d0b0a38d607"
      },
      "source": [
        "# Original Array\r\n",
        "array = np.random.randint(7, size=(3,4,5))\r\n",
        "print('Original array:\\n', array, '\\n')\r\n",
        "\r\n",
        "# Indexing to access individual elements in the array\r\n",
        "print('array[0][0][0]\\n', array[0][0][0], '\\n\\n')\r\n",
        "print('array[1,2,3]\\n', array[1,2,3]), '\\n\\n'\r\n",
        "print('array[-1,-1][-1]\\n', array[-1,-1][-1], '\\n\\n')\r\n",
        "\r\n",
        "# Array Slicing\r\n",
        "print(\"Indexing the array\")\r\n",
        "print('array[0]\\n', array[0], '\\n\\n') #extracting all elements from first axis at zeroth location\r\n",
        "print('array[:1]\\n', array[:1], '\\n\\n') \r\n",
        "print('array[:,1]\\n', array[:,1], '\\n\\n')\r\n",
        "print('array[:,:,3]\\n', array[:,:,3], '\\n\\n')\r\n",
        "print('array[:,:,-2:]\\n', array[:,:,-2:], '\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array:\n",
            " [[[1 0 2 4 3]\n",
            "  [6 3 2 4 2]\n",
            "  [0 0 4 5 5]\n",
            "  [6 0 4 1 4]]\n",
            "\n",
            " [[1 2 2 0 1]\n",
            "  [1 1 1 3 6]\n",
            "  [3 6 2 3 0]\n",
            "  [6 3 5 4 1]]\n",
            "\n",
            " [[2 4 3 4 6]\n",
            "  [4 4 3 4 4]\n",
            "  [4 0 6 4 3]\n",
            "  [2 5 5 5 0]]] \n",
            "\n",
            "array[0][0][0]\n",
            " 1 \n",
            "\n",
            "\n",
            "array[1,2,3]\n",
            " 3\n",
            "array[-1,-1][-1]\n",
            " 0 \n",
            "\n",
            "\n",
            "Indexing the array\n",
            "array[0]\n",
            " [[1 0 2 4 3]\n",
            " [6 3 2 4 2]\n",
            " [0 0 4 5 5]\n",
            " [6 0 4 1 4]] \n",
            "\n",
            "\n",
            "array[:1]\n",
            " [[[1 0 2 4 3]\n",
            "  [6 3 2 4 2]\n",
            "  [0 0 4 5 5]\n",
            "  [6 0 4 1 4]]] \n",
            "\n",
            "\n",
            "array[:,1]\n",
            " [[6 3 2 4 2]\n",
            " [1 1 1 3 6]\n",
            " [4 4 3 4 4]] \n",
            "\n",
            "\n",
            "array[:,:,3]\n",
            " [[4 4 5 1]\n",
            " [0 3 3 4]\n",
            " [4 4 4 5]] \n",
            "\n",
            "\n",
            "array[:,:,-2:]\n",
            " [[[4 3]\n",
            "  [4 2]\n",
            "  [5 5]\n",
            "  [1 4]]\n",
            "\n",
            " [[0 1]\n",
            "  [3 6]\n",
            "  [3 0]\n",
            "  [4 1]]\n",
            "\n",
            " [[4 6]\n",
            "  [4 4]\n",
            "  [4 3]\n",
            "  [5 0]]] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vlpFvSH6sSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78fc664-9291-4de8-9591-90794fa79338"
      },
      "source": [
        "# Original Tensor\n",
        "t = torch.rand(size=(3,4,5))\n",
        "print('Original Tensor t:', t, '\\n')\n",
        "\n",
        "# Indexing to access individual elements in the tensor\n",
        "print('t[0][0][0]\\n', t[0][0][0])\n",
        "print('t[1,2,3]\\n', t[1,2,3])\n",
        "print('t[-1,-1][-1]\\n', t[-1,-1][-1])\n",
        "print('\\n')\n",
        "\n",
        "# Tensor Slicing\n",
        "print(\"Indexing the tensor\")\n",
        "print('t[0]\\n', t[0])\n",
        "print('t[:1]\\n', t[:1])\n",
        "print('t[:,1]\\n', t[:,1])\n",
        "print('t[:,:,3]\\n', t[:,:,3])\n",
        "print('t[:,:,-2:]\\n', t[:,:,-2:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Tensor t: tensor([[[0.0223, 0.1689, 0.2939, 0.5185, 0.6977],\n",
            "         [0.8000, 0.1610, 0.2823, 0.6816, 0.9152],\n",
            "         [0.3971, 0.8742, 0.4194, 0.5529, 0.9527],\n",
            "         [0.0362, 0.1852, 0.3734, 0.3051, 0.9320]],\n",
            "\n",
            "        [[0.1759, 0.2698, 0.1507, 0.0317, 0.2081],\n",
            "         [0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "         [0.5846, 0.0332, 0.1387, 0.2422, 0.8155],\n",
            "         [0.7932, 0.2783, 0.4820, 0.8198, 0.9971]],\n",
            "\n",
            "        [[0.6984, 0.5675, 0.8352, 0.2056, 0.5932],\n",
            "         [0.1123, 0.1535, 0.2417, 0.7262, 0.7011],\n",
            "         [0.2038, 0.6511, 0.7745, 0.4369, 0.5191],\n",
            "         [0.6159, 0.8102, 0.9801, 0.1147, 0.3168]]]) \n",
            "\n",
            "t[0][0][0]\n",
            " tensor(0.0223)\n",
            "t[1,2,3]\n",
            " tensor(0.2422)\n",
            "t[-1,-1][-1]\n",
            " tensor(0.3168)\n",
            "\n",
            "\n",
            "Indexing the tensor\n",
            "t[0]\n",
            " tensor([[0.0223, 0.1689, 0.2939, 0.5185, 0.6977],\n",
            "        [0.8000, 0.1610, 0.2823, 0.6816, 0.9152],\n",
            "        [0.3971, 0.8742, 0.4194, 0.5529, 0.9527],\n",
            "        [0.0362, 0.1852, 0.3734, 0.3051, 0.9320]])\n",
            "t[:1]\n",
            " tensor([[[0.0223, 0.1689, 0.2939, 0.5185, 0.6977],\n",
            "         [0.8000, 0.1610, 0.2823, 0.6816, 0.9152],\n",
            "         [0.3971, 0.8742, 0.4194, 0.5529, 0.9527],\n",
            "         [0.0362, 0.1852, 0.3734, 0.3051, 0.9320]]])\n",
            "t[:,1]\n",
            " tensor([[0.8000, 0.1610, 0.2823, 0.6816, 0.9152],\n",
            "        [0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "        [0.1123, 0.1535, 0.2417, 0.7262, 0.7011]])\n",
            "t[:,:,3]\n",
            " tensor([[0.5185, 0.6816, 0.5529, 0.3051],\n",
            "        [0.0317, 0.5263, 0.2422, 0.8198],\n",
            "        [0.2056, 0.7262, 0.4369, 0.1147]])\n",
            "t[:,:,-2:]\n",
            " tensor([[[0.5185, 0.6977],\n",
            "         [0.6816, 0.9152],\n",
            "         [0.5529, 0.9527],\n",
            "         [0.3051, 0.9320]],\n",
            "\n",
            "        [[0.0317, 0.2081],\n",
            "         [0.5263, 0.2437],\n",
            "         [0.2422, 0.8155],\n",
            "         [0.8198, 0.9971]],\n",
            "\n",
            "        [[0.2056, 0.5932],\n",
            "         [0.7262, 0.7011],\n",
            "         [0.4369, 0.5191],\n",
            "         [0.1147, 0.3168]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aiKETU39GAP"
      },
      "source": [
        "## **4. Pivoting Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eyCrBkCjiE_"
      },
      "source": [
        "In the following section we cover common methods used to pivot and reshape arrays/tensors, namely:\r\n",
        "1. Flatten\r\n",
        "1. Squeeze\r\n",
        "1. Reshape\r\n",
        "1. Transpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KGza-uyr8m2"
      },
      "source": [
        "**NOTE:**  The size and shape of an array/tensor mean the same thing.\r\n",
        "\r\n",
        "Typically, after we know an array/tensor’s shape, we can deduce a couple of things. First, we can deduce the array/tensor's rank. The rank of an array/tensor is equal to the length of the tensor's shape.\r\n",
        "\r\n",
        "We can also deduce the number of elements contained within the tensor. The number of elements inside an array/tensor is equal to the product of the shape's component values.\r\n",
        "\r\n",
        "The number of elements contained within an array/tensor is important for reshaping because the reshaping must account for the total number of elements present. Reshaping changes the array/tensor's shape but not the underlying data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HryEr9zekQOw"
      },
      "source": [
        "### 4a. Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSaVBTQVlZ9H"
      },
      "source": [
        "A flatten operation on an array/tensor reshapes the array/tensor to have a shape that is equal to the number of elements contained in the array/tensor. Flattening an array/tensor means to remove all of the dimensions except for one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZX1gtGltdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e0bb14-47f3-45f0-aa6a-6247e864e8e3"
      },
      "source": [
        "# Flatten a Numpy Array\r\n",
        "\r\n",
        "original_array = np.random.randint(3, size = (2, 3, 4)) \r\n",
        "print(original_array, \"\\n\", \"The dimension of the original array is:\", original_array.shape, \"\\n\") \r\n",
        "\r\n",
        "flattened_array = original_array.flatten()\r\n",
        "print(flattened_array, \"\\n\", \"The dimension of the flattened array is:\", flattened_array.shape, \"\\n\") # Should be 2*3*4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1 1 1 0]\n",
            "  [1 2 0 1]\n",
            "  [2 0 2 0]]\n",
            "\n",
            " [[1 2 2 1]\n",
            "  [0 1 1 0]\n",
            "  [2 2 2 2]]] \n",
            " The dimension of the original array is: (2, 3, 4) \n",
            "\n",
            "[1 1 1 0 1 2 0 1 2 0 2 0 1 2 2 1 0 1 1 0 2 2 2 2] \n",
            " The dimension of the flattened array is: (24,) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RcxSRS8mv__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e008d46-10ea-4958-86ed-77f1146522db"
      },
      "source": [
        "# Flatten a Torch Tensor\r\n",
        "\r\n",
        "original_tensor = torch.rand(size=(2, 3, 4))\r\n",
        "print(original_tensor, \"\\n\", \"The dimension of the original tensor is:\", original_tensor.shape, \"\\n\") \r\n",
        "\r\n",
        "flattened_tensor = original_tensor.flatten()\r\n",
        "print(flattened_tensor, \"\\n\", \"The dimension of the flattened tensor is:\", flattened_tensor.shape, \"\\n\") # Should be 2*3*4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.6965, 0.9143, 0.9351, 0.9412],\n",
            "         [0.5995, 0.0652, 0.5460, 0.1872],\n",
            "         [0.0340, 0.9442, 0.8802, 0.0012]],\n",
            "\n",
            "        [[0.5936, 0.4158, 0.4177, 0.2711],\n",
            "         [0.6923, 0.2038, 0.6833, 0.7529],\n",
            "         [0.8579, 0.6870, 0.0051, 0.1757]]]) \n",
            " The dimension of the original tensor is: torch.Size([2, 3, 4]) \n",
            "\n",
            "tensor([0.6965, 0.9143, 0.9351, 0.9412, 0.5995, 0.0652, 0.5460, 0.1872, 0.0340,\n",
            "        0.9442, 0.8802, 0.0012, 0.5936, 0.4158, 0.4177, 0.2711, 0.6923, 0.2038,\n",
            "        0.6833, 0.7529, 0.8579, 0.6870, 0.0051, 0.1757]) \n",
            " The dimension of the flattened tensor is: torch.Size([24]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snNG-wGZnl_X"
      },
      "source": [
        "### 4b. Squeeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqmkUenooN4B"
      },
      "source": [
        "The next way we can change the shape of our arrays/tensors is by squeezing and unsqueezing them.\r\n",
        "\r\n",
        "*   Squeezing an array/tensor removes the dimensions or axes that have a length of one.\r\n",
        "*   Unsqueezing an array/tensor adds a dimension with a length of one.\r\n",
        "\r\n",
        "These functions allow us to expand or shrink the rank (number of dimensions) of our array/tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdhYbZs3pLsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0d772c-f11a-4db4-a180-7b87410e707c"
      },
      "source": [
        "# Original Array\r\n",
        "original_array = np.random.randint(3, size = (6, 1, 3))\r\n",
        "print(\"Example of array with single dimension in one of the axis \\n\", original_array,'\\n')\r\n",
        "\r\n",
        "# Squeeze a Numpy Array\r\n",
        "\r\n",
        "squeezed_array = np.squeeze(original_array, axis = 1)\r\n",
        "print(\"The squeezed array is \\n\",  squeezed_array, \"\\n and the dimension is\", squeezed_array.shape,'\\n')\r\n",
        "\r\n",
        "# Unsqueeze a Numpy Array\r\n",
        "\r\n",
        "unsqueezed_array = np.expand_dims(squeezed_array, axis = 1) # can specify which axes by using 'axis = '\r\n",
        "print(\"The unsqueezed array is \\n\",  unsqueezed_array, \"\\n and the dimension is\", unsqueezed_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of array with single dimension in one of the axis \n",
            " [[[1 2 2]]\n",
            "\n",
            " [[2 2 2]]\n",
            "\n",
            " [[0 1 2]]\n",
            "\n",
            " [[2 1 2]]\n",
            "\n",
            " [[1 0 2]]\n",
            "\n",
            " [[2 0 2]]] \n",
            "\n",
            "The squeezed array is \n",
            " [[1 2 2]\n",
            " [2 2 2]\n",
            " [0 1 2]\n",
            " [2 1 2]\n",
            " [1 0 2]\n",
            " [2 0 2]] \n",
            " and the dimension is (6, 3) \n",
            "\n",
            "The unsqueezed array is \n",
            " [[[1 2 2]]\n",
            "\n",
            " [[2 2 2]]\n",
            "\n",
            " [[0 1 2]]\n",
            "\n",
            " [[2 1 2]]\n",
            "\n",
            " [[1 0 2]]\n",
            "\n",
            " [[2 0 2]]] \n",
            " and the dimension is (6, 1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeDhMjhIsDpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179a2d75-446d-47ff-d19f-01742a57f198"
      },
      "source": [
        "# Original Tensor\r\n",
        "original_tensor = torch.rand(size=(3, 2, 1, 2))\r\n",
        "print(\"Example of tensor with single dimension in one of the axis \\n\", original_tensor,'\\n')\r\n",
        "\r\n",
        "# Squeeze a Torch Tensor\r\n",
        "\r\n",
        "squeezed_tensor = original_tensor.squeeze(2)\r\n",
        "print(\"The squeezed tensor is \\n\",  squeezed_tensor, \"\\n and the dimension is\", squeezed_tensor.shape,'\\n')\r\n",
        "\r\n",
        "# Unsqueeze a Torch Tensor\r\n",
        "\r\n",
        "unsqueezed_tensor = squeezed_tensor.unsqueeze(2) \r\n",
        "print(\"The unsqueezed tensor is \\n\",  unsqueezed_tensor, \"\\n and the dimension is\", unsqueezed_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of tensor with single dimension in one of the axis \n",
            " tensor([[[[0.7497, 0.6047]],\n",
            "\n",
            "         [[0.1100, 0.2121]]],\n",
            "\n",
            "\n",
            "        [[[0.9704, 0.8369]],\n",
            "\n",
            "         [[0.2820, 0.3742]]],\n",
            "\n",
            "\n",
            "        [[[0.0237, 0.4910]],\n",
            "\n",
            "         [[0.1235, 0.1143]]]]) \n",
            "\n",
            "The squeezed tensor is \n",
            " tensor([[[0.7497, 0.6047],\n",
            "         [0.1100, 0.2121]],\n",
            "\n",
            "        [[0.9704, 0.8369],\n",
            "         [0.2820, 0.3742]],\n",
            "\n",
            "        [[0.0237, 0.4910],\n",
            "         [0.1235, 0.1143]]]) \n",
            " and the dimension is torch.Size([3, 2, 2]) \n",
            "\n",
            "The unsqueezed tensor is \n",
            " tensor([[[[0.7497, 0.6047]],\n",
            "\n",
            "         [[0.1100, 0.2121]]],\n",
            "\n",
            "\n",
            "        [[[0.9704, 0.8369]],\n",
            "\n",
            "         [[0.2820, 0.3742]]],\n",
            "\n",
            "\n",
            "        [[[0.0237, 0.4910]],\n",
            "\n",
            "         [[0.1235, 0.1143]]]]) \n",
            " and the dimension is torch.Size([3, 2, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MGpfGHRp_rK"
      },
      "source": [
        "### 4c. Reshape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPHgBulPseAc"
      },
      "source": [
        "Using the reshape() function, we can specify the shape that we are seeking. Notice how all of the shapes have to account for the number of elements in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa9QEB7Xtl_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576c29fa-04ac-4296-c090-82a1e2f4997c"
      },
      "source": [
        "# Reshaping a Numpy Array\r\n",
        "\r\n",
        "original_array = np.random.randint(3, size = (2, 3, 4)) \r\n",
        "print(original_array, \"\\n\", \"The dimension of the original array is:\", original_array.shape, \"\\n\") \r\n",
        "\r\n",
        "reshaped_array1 = np.reshape(original_array, (4, 2, 3))\r\n",
        "print(reshaped_array1, \"\\n\", \"The dimension of the reshaped array is:\", reshaped_array1.shape, \"\\n\") # Product of size should be same as orginal\r\n",
        "\r\n",
        "reshaped_array2 = np.reshape(original_array, (6, 4))\r\n",
        "print(reshaped_array2, \"\\n\", \"The dimension of the reshaped array is:\", reshaped_array2.shape, \"\\n\") # Product of size should be same as orginal\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 2 0]\n",
            "  [2 2 2 0]\n",
            "  [0 0 1 2]]\n",
            "\n",
            " [[0 1 2 2]\n",
            "  [2 1 0 0]\n",
            "  [0 0 2 2]]] \n",
            " The dimension of the original array is: (2, 3, 4) \n",
            "\n",
            "[[[0 0 2]\n",
            "  [0 2 2]]\n",
            "\n",
            " [[2 0 0]\n",
            "  [0 1 2]]\n",
            "\n",
            " [[0 1 2]\n",
            "  [2 2 1]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 2 2]]] \n",
            " The dimension of the reshaped array is: (4, 2, 3) \n",
            "\n",
            "[[0 0 2 0]\n",
            " [2 2 2 0]\n",
            " [0 0 1 2]\n",
            " [0 1 2 2]\n",
            " [2 1 0 0]\n",
            " [0 0 2 2]] \n",
            " The dimension of the reshaped array is: (6, 4) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDPRvgd93e-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41f376f-3298-4b4c-facb-87ca7aa189bc"
      },
      "source": [
        "# Reshaping a Torch Tensor\r\n",
        "\r\n",
        "original_tensor = torch.rand(size=(3, 1, 2, 2))\r\n",
        "print(original_tensor, \"\\n\", \"The dimension of the original tensor is:\", original_tensor.shape, \"\\n\") \r\n",
        "\r\n",
        "reshaped_tensor1 = original_tensor.reshape(3, 4, 1)\r\n",
        "print(reshaped_tensor1, \"\\n\", \"The dimension of the reshaped tensor is:\", reshaped_tensor1.shape, \"\\n\") # Product of size should be same as orginal\r\n",
        "\r\n",
        "reshaped_tensor2 = original_tensor.reshape(2, 6)\r\n",
        "print(reshaped_tensor2, \"\\n\", \"The dimension of the reshaped tensor is:\", reshaped_tensor2.shape, \"\\n\") # Product of size should be same as orginal\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.4725, 0.5751],\n",
            "          [0.2952, 0.7967]]],\n",
            "\n",
            "\n",
            "        [[[0.1957, 0.9537],\n",
            "          [0.8426, 0.0784]]],\n",
            "\n",
            "\n",
            "        [[[0.3756, 0.5226],\n",
            "          [0.5730, 0.6186]]]]) \n",
            " The dimension of the original tensor is: torch.Size([3, 1, 2, 2]) \n",
            "\n",
            "tensor([[[0.4725],\n",
            "         [0.5751],\n",
            "         [0.2952],\n",
            "         [0.7967]],\n",
            "\n",
            "        [[0.1957],\n",
            "         [0.9537],\n",
            "         [0.8426],\n",
            "         [0.0784]],\n",
            "\n",
            "        [[0.3756],\n",
            "         [0.5226],\n",
            "         [0.5730],\n",
            "         [0.6186]]]) \n",
            " The dimension of the reshaped tensor is: torch.Size([3, 4, 1]) \n",
            "\n",
            "tensor([[0.4725, 0.5751, 0.2952, 0.7967, 0.1957, 0.9537],\n",
            "        [0.8426, 0.0784, 0.3756, 0.5226, 0.5730, 0.6186]]) \n",
            " The dimension of the reshaped tensor is: torch.Size([2, 6]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOs5sroczwgk"
      },
      "source": [
        "**Special Case:** Numpy/Pytorch allow us to give one of new shape parameter as -1 (eg: (2,-1) or (-1,3) but not (-1, -1)). It simply means that it is an unknown dimension and we want numpy/pytorch to figure it out. Numpy/Pytorch will figure this by looking at the 'length of the array and remaining dimensions' and making sure it satisfies the above mentioned criteria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfB7iG5h6jI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364d7b17-40a8-4600-de66-cd3845b5d201"
      },
      "source": [
        "# Reshaping a Numpy Array with -1\r\n",
        "\r\n",
        "original_array = np.random.randint(3, size = (2, 3, 4)) \r\n",
        "print(original_array, \"\\n\", \"The dimension of the original array is:\", original_array.shape, \"\\n\") \r\n",
        "\r\n",
        "reshaped_array1 = np.reshape(original_array, (4, -1, 3)) # Numpy will automatically infer that the missing size is 2\r\n",
        "print(reshaped_array1, \"\\n\", \"The dimension of the reshaped array is:\", reshaped_array1.shape, \"\\n\") # Product of size should be same as orginal\r\n",
        "\r\n",
        "reshaped_array2 = np.reshape(original_array, (-1)) # Numpy will automatically infer that the missing size is 24\r\n",
        "print(reshaped_array2, \"\\n\", \"The dimension of the reshaped array is:\", reshaped_array2.shape, \"\\n\") # Product of size should be same as orginal\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 1]\n",
            "  [2 0 0 1]\n",
            "  [0 2 1 1]]\n",
            "\n",
            " [[1 0 0 0]\n",
            "  [1 1 2 1]\n",
            "  [0 0 1 2]]] \n",
            " The dimension of the original array is: (2, 3, 4) \n",
            "\n",
            "[[[0 0 0]\n",
            "  [1 2 0]]\n",
            "\n",
            " [[0 1 0]\n",
            "  [2 1 1]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 1]]\n",
            "\n",
            " [[2 1 0]\n",
            "  [0 1 2]]] \n",
            " The dimension of the reshaped array is: (4, 2, 3) \n",
            "\n",
            "[0 0 0 1 2 0 0 1 0 2 1 1 1 0 0 0 1 1 2 1 0 0 1 2] \n",
            " The dimension of the reshaped array is: (24,) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVIygQ9V65G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8367a9c3-089a-4bc7-b759-dd7ab2a06c39"
      },
      "source": [
        "# Reshaping a Torch Tensor with -1\r\n",
        "\r\n",
        "original_tensor = torch.rand(size=(3, 2, 1, 2))\r\n",
        "print(original_tensor, \"\\n\", \"The dimension of the original tensor is:\", original_tensor.shape, \"\\n\") \r\n",
        "\r\n",
        "reshaped_tensor1 = original_tensor.reshape(3, -1, 1) # Torch will automatically infer that the missing size is 4\r\n",
        "print(reshaped_tensor1, \"\\n\", \"The dimension of the reshaped tensor is:\", reshaped_tensor1.shape, \"\\n\") # Product of size should be same as orginal\r\n",
        "\r\n",
        "reshaped_tensor2 = original_tensor.reshape(-1) # Torch will automatically infer that the missing size is 12\r\n",
        "print(reshaped_tensor2, \"\\n\", \"The dimension of the reshaped tensor is:\", reshaped_tensor2.shape, \"\\n\") # Product of size should be same as orginal\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.6962, 0.5300]],\n",
            "\n",
            "         [[0.2560, 0.7366]]],\n",
            "\n",
            "\n",
            "        [[[0.0204, 0.2036]],\n",
            "\n",
            "         [[0.3748, 0.2564]]],\n",
            "\n",
            "\n",
            "        [[[0.3251, 0.0902]],\n",
            "\n",
            "         [[0.3936, 0.6069]]]]) \n",
            " The dimension of the original tensor is: torch.Size([3, 2, 1, 2]) \n",
            "\n",
            "tensor([[[0.6962],\n",
            "         [0.5300],\n",
            "         [0.2560],\n",
            "         [0.7366]],\n",
            "\n",
            "        [[0.0204],\n",
            "         [0.2036],\n",
            "         [0.3748],\n",
            "         [0.2564]],\n",
            "\n",
            "        [[0.3251],\n",
            "         [0.0902],\n",
            "         [0.3936],\n",
            "         [0.6069]]]) \n",
            " The dimension of the reshaped tensor is: torch.Size([3, 4, 1]) \n",
            "\n",
            "tensor([0.6962, 0.5300, 0.2560, 0.7366, 0.0204, 0.2036, 0.3748, 0.2564, 0.3251,\n",
            "        0.0902, 0.3936, 0.6069]) \n",
            " The dimension of the reshaped tensor is: torch.Size([12]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVcUpWW86gkW"
      },
      "source": [
        "**HINT!!** Reshape(-1) essentially does the same things as Flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n0ReEbp8856"
      },
      "source": [
        "### 4d. Transpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEpachh3Hitl"
      },
      "source": [
        "**NUMPY:** If the axes are specified, it must be a tuple or list which contains a permutation of [0,1,..,N-1] where N is the number of axes of the array. The i’th axis of the returned array will correspond to the axis numbered axes[i] of the input. If not specified, defaults to range(a.ndim)[::-1], which reverses the order of the axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhyrnt0T--xE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed920f32-1e44-411a-9767-8b87b21aed40"
      },
      "source": [
        "# Transposing a Numpy Array\r\n",
        "\r\n",
        "original_array = np.random.randint(3, size = (2, 3)) \r\n",
        "print(original_array, \"\\n\", \"The dimension of the original array is:\", original_array.shape, \"\\n\") \r\n",
        "\r\n",
        "transposed_array1 = np.transpose(original_array) # If left empty, prefrom matrix transposition\r\n",
        "print(transposed_array1, \"\\n\", \"The dimension of the transposed array is:\", transposed_array1.shape, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1]\n",
            " [0 0 0]] \n",
            " The dimension of the original array is: (2, 3) \n",
            "\n",
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]] \n",
            " The dimension of the transposed array is: (3, 2) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj6lmIn_LmNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7531ad48-27bc-4d8f-dfc6-afc0c3e14453"
      },
      "source": [
        "example_array = np.array([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "print(example_array, \"\\n\", \"The dimension of this example array is:\", example_array.shape, \"\\n\") \r\n",
        "\r\n",
        "transposed_exampleX = np.transpose(example_array, axes = (0,1,2)) # axes tuple must be of size n-1 where n = rank of array (3 in this case)\r\n",
        "print(transposed_exampleX, \"\\n\", \"The dimension of the transposed array (0,1,2) is:\", transposed_exampleX.shape, \"\\n\") # nothing has changed here\r\n",
        "\r\n",
        "transposed_example1 = np.transpose(example_array, axes = (1,0,2)) \r\n",
        "print(transposed_example1, \"\\n\", \"The dimension of the transposed array (1,0,2) is:\", transposed_example1.shape, \"\\n\")\r\n",
        "\r\n",
        "transposed_example2 = np.transpose(example_array, axes = (2,1,0))\r\n",
        "print(transposed_example2, \"\\n\", \"The dimension of the transposed array (2,1,0) is:\", transposed_example2.shape, \"\\n\")\r\n",
        "\r\n",
        "transposed_example3 = np.transpose(example_array, axes = (1,0,2))\r\n",
        "print(transposed_example3, \"\\n\", \"The dimension of the transposed array (1,0,2) is:\", transposed_example3.shape, \"\\n\")\r\n",
        "\r\n",
        "transposed_example4 = np.transpose(example_array, axes = (1,2,0)) \r\n",
        "print(transposed_example4, \"\\n\", \"The dimension of the transposed array (1,2,0) is:\", transposed_example4.shape, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[  1   2   3   4]\n",
            "  [  5   6   7   8]\n",
            "  [  9  10  11  12]]\n",
            "\n",
            " [[ -1  -2  -3  -4]\n",
            "  [ -5  -6  -7  -8]\n",
            "  [ -9 -10 -11 -12]]] \n",
            " The dimension of this example array is: (2, 3, 4) \n",
            "\n",
            "[[[  1   2   3   4]\n",
            "  [  5   6   7   8]\n",
            "  [  9  10  11  12]]\n",
            "\n",
            " [[ -1  -2  -3  -4]\n",
            "  [ -5  -6  -7  -8]\n",
            "  [ -9 -10 -11 -12]]] \n",
            " The dimension of the transposed array (0,1,2) is: (2, 3, 4) \n",
            "\n",
            "[[[  1   2   3   4]\n",
            "  [ -1  -2  -3  -4]]\n",
            "\n",
            " [[  5   6   7   8]\n",
            "  [ -5  -6  -7  -8]]\n",
            "\n",
            " [[  9  10  11  12]\n",
            "  [ -9 -10 -11 -12]]] \n",
            " The dimension of the transposed array (1,0,2) is: (3, 2, 4) \n",
            "\n",
            "[[[  1  -1]\n",
            "  [  5  -5]\n",
            "  [  9  -9]]\n",
            "\n",
            " [[  2  -2]\n",
            "  [  6  -6]\n",
            "  [ 10 -10]]\n",
            "\n",
            " [[  3  -3]\n",
            "  [  7  -7]\n",
            "  [ 11 -11]]\n",
            "\n",
            " [[  4  -4]\n",
            "  [  8  -8]\n",
            "  [ 12 -12]]] \n",
            " The dimension of the transposed array (2,1,0) is: (4, 3, 2) \n",
            "\n",
            "[[[  1   2   3   4]\n",
            "  [ -1  -2  -3  -4]]\n",
            "\n",
            " [[  5   6   7   8]\n",
            "  [ -5  -6  -7  -8]]\n",
            "\n",
            " [[  9  10  11  12]\n",
            "  [ -9 -10 -11 -12]]] \n",
            " The dimension of the transposed array (1,0,2) is: (3, 2, 4) \n",
            "\n",
            "[[[  1  -1]\n",
            "  [  2  -2]\n",
            "  [  3  -3]\n",
            "  [  4  -4]]\n",
            "\n",
            " [[  5  -5]\n",
            "  [  6  -6]\n",
            "  [  7  -7]\n",
            "  [  8  -8]]\n",
            "\n",
            " [[  9  -9]\n",
            "  [ 10 -10]\n",
            "  [ 11 -11]\n",
            "  [ 12 -12]]] \n",
            " The dimension of the transposed array (1,2,0) is: (3, 4, 2) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDUPUI7NHvVF"
      },
      "source": [
        "**PYTORCH:** Returns a tensor that is a transposed version of input. The given dimensions are swapped. The resulting tensor shares it’s underlying storage with the input tensor, so changing the content of one would change the content of the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llpmRC6AIFJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292ba9b6-9f95-4fd7-f8bf-28367a98e62f"
      },
      "source": [
        "# Transposing a Torch Tensor\r\n",
        "\r\n",
        "original_tensor = torch.rand(size=(2, 3))\r\n",
        "print(original_tensor, \"\\n\", \"The dimension of the original tensor is:\", original_tensor.shape, \"\\n\") \r\n",
        "\r\n",
        "transposed_tensor1 = original_tensor.transpose(0,1) # Cannot be left empty - would also be the same as original_tensor.transpose(1, 0)\r\n",
        "print(transposed_tensor1, \"\\n\", \"The dimension of the transposed tensor is:\", transposed_tensor1.shape, \"\\n\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1743, 0.4743, 0.8579],\n",
            "        [0.4486, 0.5139, 0.4569]]) \n",
            " The dimension of the original tensor is: torch.Size([2, 3]) \n",
            "\n",
            "tensor([[0.1743, 0.4486],\n",
            "        [0.4743, 0.5139],\n",
            "        [0.8579, 0.4569]]) \n",
            " The dimension of the transposed tensor is: torch.Size([3, 2]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNs1y7O-Lq4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4faf2b-5d0a-44f1-9add-2b14e05d4654"
      },
      "source": [
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "print(example_tensor, \"\\n\", \"The dimension of this example tensor is:\", example_tensor.shape, \"\\n\") \r\n",
        "\r\n",
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "transposed_example1 = example_tensor.transpose(0,1)\r\n",
        "print(transposed_example1, \"\\n\", \"The dimension of the transposed tensor (0,1,2) is:\", transposed_example1.shape, \"\\n\")\r\n",
        "\r\n",
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "transposed_example2 = example_tensor.transpose(0,2)\r\n",
        "print(transposed_example2, \"\\n\", \"The dimension of the transposed tensor (1,0,2) is:\", transposed_example2.shape, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[  1,   2,   3,   4],\n",
            "         [  5,   6,   7,   8],\n",
            "         [  9,  10,  11,  12]],\n",
            "\n",
            "        [[ -1,  -2,  -3,  -4],\n",
            "         [ -5,  -6,  -7,  -8],\n",
            "         [ -9, -10, -11, -12]]]) \n",
            " The dimension of this example tensor is: torch.Size([2, 3, 4]) \n",
            "\n",
            "tensor([[[  1,   2,   3,   4],\n",
            "         [ -1,  -2,  -3,  -4]],\n",
            "\n",
            "        [[  5,   6,   7,   8],\n",
            "         [ -5,  -6,  -7,  -8]],\n",
            "\n",
            "        [[  9,  10,  11,  12],\n",
            "         [ -9, -10, -11, -12]]]) \n",
            " The dimension of the transposed tensor (0,1,2) is: torch.Size([3, 2, 4]) \n",
            "\n",
            "tensor([[[  1,  -1],\n",
            "         [  5,  -5],\n",
            "         [  9,  -9]],\n",
            "\n",
            "        [[  2,  -2],\n",
            "         [  6,  -6],\n",
            "         [ 10, -10]],\n",
            "\n",
            "        [[  3,  -3],\n",
            "         [  7,  -7],\n",
            "         [ 11, -11]],\n",
            "\n",
            "        [[  4,  -4],\n",
            "         [  8,  -8],\n",
            "         [ 12, -12]]]) \n",
            " The dimension of the transposed tensor (1,0,2) is: torch.Size([4, 3, 2]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpuCgujs95kH"
      },
      "source": [
        "**NOTE:** For Torch, the *permute* operation operation allows the user to simultaneously reorder multiple dimensions unlike *transpose* which interchanges two dimensions only. \r\n",
        "\r\n",
        "PyTorch torch.permute() rearranges the original tensor according to the desired ordering and returns a new multidimensional rotated tensor. The size of the returned tensor remains the same as that of the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47puocJTKk3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1be6fe-b6c3-459f-f51a-e6a6be90a0e2"
      },
      "source": [
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "transposed_exampleX = example_tensor.permute(0,1,2)\r\n",
        "print(transposed_exampleX, \"\\n\", \"The dimension of the transposed tensor (0,1,2) is:\", transposed_exampleX.shape, \"\\n\") # nothing has changed here\r\n",
        "\r\n",
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "transposed_example3 = example_tensor.permute(1,0,2)\r\n",
        "print(transposed_example3, \"\\n\", \"The dimension of the transposed tensor (1,0,2) is:\", transposed_example3.shape, \"\\n\")\r\n",
        "\r\n",
        "example_tensor = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[-1,-2,-3,-4],[-5,-6,-7,-8],[-9,-10,-11,-12]]])\r\n",
        "transposed_example4 = example_tensor.permute(1,2,0)\r\n",
        "print(transposed_example4, \"\\n\", \"The dimension of the transposed tensor (1,2,0) is:\", transposed_example4.shape, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[  1,   2,   3,   4],\n",
            "         [  5,   6,   7,   8],\n",
            "         [  9,  10,  11,  12]],\n",
            "\n",
            "        [[ -1,  -2,  -3,  -4],\n",
            "         [ -5,  -6,  -7,  -8],\n",
            "         [ -9, -10, -11, -12]]]) \n",
            " The dimension of the transposed tensor (0,1,2) is: torch.Size([2, 3, 4]) \n",
            "\n",
            "tensor([[[  1,   2,   3,   4],\n",
            "         [ -1,  -2,  -3,  -4]],\n",
            "\n",
            "        [[  5,   6,   7,   8],\n",
            "         [ -5,  -6,  -7,  -8]],\n",
            "\n",
            "        [[  9,  10,  11,  12],\n",
            "         [ -9, -10, -11, -12]]]) \n",
            " The dimension of the transposed tensor (1,0,2) is: torch.Size([3, 2, 4]) \n",
            "\n",
            "tensor([[[  1,  -1],\n",
            "         [  2,  -2],\n",
            "         [  3,  -3],\n",
            "         [  4,  -4]],\n",
            "\n",
            "        [[  5,  -5],\n",
            "         [  6,  -6],\n",
            "         [  7,  -7],\n",
            "         [  8,  -8]],\n",
            "\n",
            "        [[  9,  -9],\n",
            "         [ 10, -10],\n",
            "         [ 11, -11],\n",
            "         [ 12, -12]]]) \n",
            " The dimension of the transposed tensor (1,2,0) is: torch.Size([3, 4, 2]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2SjC78OXA6V"
      },
      "source": [
        "## **5. Combining Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3VQjk8OXMm"
      },
      "source": [
        "In the following section we cover common methods used to combine data in arrays/tensors, namely:\r\n",
        "1. Concatenation\r\n",
        "2. Stack\r\n",
        "3. Repeat\r\n",
        "4. Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGMXvS3HRuB0"
      },
      "source": [
        "### 5a. Concatenation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Xu3omVRzhe"
      },
      "source": [
        "A concatenation operation joins a sequence of arrays/tensors along an *existing* axis. All arrays/tensors must either have the same shape (except in the concatenating dimension) or be empty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKohuN6ySITt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffc5478-c1f9-4d06-8f32-fcdc2840d214"
      },
      "source": [
        "# Concatenating Numpy Arrays\r\n",
        "\r\n",
        "array1 = np.random.randint(3, size = (3, 4, 5))\r\n",
        "print(\"Array 1 is \\n\", array1, \" with dimensions \", array1.shape, \"\\n\")\r\n",
        "\r\n",
        "array2 = np.random.randint(4, size = (3, 4, 5))\r\n",
        "print(\"Array 2 is \\n\", array2, \" with dimensions \", array2.shape, \"\\n\")\r\n",
        "\r\n",
        "concatenated_array1 = np.concatenate((array1, array2), axis = 0) \r\n",
        "print(\"Concatenated array 1 is \\n\", concatenated_array1, \"\\n\\n\", \"and the dimensions of the concatenated array 1 are: \\n\", concatenated_array1.shape)\r\n",
        "\r\n",
        "concatenated_array2 = np.concatenate((array1, array2), axis = 1) \r\n",
        "print(\"Concatenated array 2 is \\n\", concatenated_array2, \"\\n\\n\", \"and the dimensions of the concatenated array 2 are: \\n\", concatenated_array2.shape)\r\n",
        "\r\n",
        "concatenated_array3 = np.concatenate((array1, array2), axis = 2) \r\n",
        "print(\"Concatenated array 3 is \\n\", concatenated_array3, \"\\n\\n\", \"and the dimensions of the concatenated array 3 are: \\n\", concatenated_array3.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array 1 is \n",
            " [[[1 2 1 1 0]\n",
            "  [0 1 2 0 2]\n",
            "  [2 1 1 1 2]\n",
            "  [0 0 1 0 2]]\n",
            "\n",
            " [[2 0 2 2 2]\n",
            "  [1 1 0 0 0]\n",
            "  [2 2 1 1 0]\n",
            "  [0 2 1 1 2]]\n",
            "\n",
            " [[0 1 1 1 1]\n",
            "  [1 2 2 2 0]\n",
            "  [1 2 1 1 1]\n",
            "  [1 0 2 2 0]]]  with dimensions  (3, 4, 5) \n",
            "\n",
            "Array 2 is \n",
            " [[[1 1 0 3 0]\n",
            "  [0 3 2 1 2]\n",
            "  [1 2 0 2 0]\n",
            "  [1 1 1 0 3]]\n",
            "\n",
            " [[0 3 0 0 0]\n",
            "  [0 1 3 3 0]\n",
            "  [3 2 2 1 1]\n",
            "  [1 2 1 1 0]]\n",
            "\n",
            " [[1 2 1 1 0]\n",
            "  [0 1 1 2 3]\n",
            "  [3 1 3 3 3]\n",
            "  [2 2 1 2 3]]]  with dimensions  (3, 4, 5) \n",
            "\n",
            "Concatenated array 1 is \n",
            " [[[1 2 1 1 0]\n",
            "  [0 1 2 0 2]\n",
            "  [2 1 1 1 2]\n",
            "  [0 0 1 0 2]]\n",
            "\n",
            " [[2 0 2 2 2]\n",
            "  [1 1 0 0 0]\n",
            "  [2 2 1 1 0]\n",
            "  [0 2 1 1 2]]\n",
            "\n",
            " [[0 1 1 1 1]\n",
            "  [1 2 2 2 0]\n",
            "  [1 2 1 1 1]\n",
            "  [1 0 2 2 0]]\n",
            "\n",
            " [[1 1 0 3 0]\n",
            "  [0 3 2 1 2]\n",
            "  [1 2 0 2 0]\n",
            "  [1 1 1 0 3]]\n",
            "\n",
            " [[0 3 0 0 0]\n",
            "  [0 1 3 3 0]\n",
            "  [3 2 2 1 1]\n",
            "  [1 2 1 1 0]]\n",
            "\n",
            " [[1 2 1 1 0]\n",
            "  [0 1 1 2 3]\n",
            "  [3 1 3 3 3]\n",
            "  [2 2 1 2 3]]] \n",
            "\n",
            " and the dimensions of the concatenated array 1 are: \n",
            " (6, 4, 5)\n",
            "Concatenated array 2 is \n",
            " [[[1 2 1 1 0]\n",
            "  [0 1 2 0 2]\n",
            "  [2 1 1 1 2]\n",
            "  [0 0 1 0 2]\n",
            "  [1 1 0 3 0]\n",
            "  [0 3 2 1 2]\n",
            "  [1 2 0 2 0]\n",
            "  [1 1 1 0 3]]\n",
            "\n",
            " [[2 0 2 2 2]\n",
            "  [1 1 0 0 0]\n",
            "  [2 2 1 1 0]\n",
            "  [0 2 1 1 2]\n",
            "  [0 3 0 0 0]\n",
            "  [0 1 3 3 0]\n",
            "  [3 2 2 1 1]\n",
            "  [1 2 1 1 0]]\n",
            "\n",
            " [[0 1 1 1 1]\n",
            "  [1 2 2 2 0]\n",
            "  [1 2 1 1 1]\n",
            "  [1 0 2 2 0]\n",
            "  [1 2 1 1 0]\n",
            "  [0 1 1 2 3]\n",
            "  [3 1 3 3 3]\n",
            "  [2 2 1 2 3]]] \n",
            "\n",
            " and the dimensions of the concatenated array 2 are: \n",
            " (3, 8, 5)\n",
            "Concatenated array 3 is \n",
            " [[[1 2 1 1 0 1 1 0 3 0]\n",
            "  [0 1 2 0 2 0 3 2 1 2]\n",
            "  [2 1 1 1 2 1 2 0 2 0]\n",
            "  [0 0 1 0 2 1 1 1 0 3]]\n",
            "\n",
            " [[2 0 2 2 2 0 3 0 0 0]\n",
            "  [1 1 0 0 0 0 1 3 3 0]\n",
            "  [2 2 1 1 0 3 2 2 1 1]\n",
            "  [0 2 1 1 2 1 2 1 1 0]]\n",
            "\n",
            " [[0 1 1 1 1 1 2 1 1 0]\n",
            "  [1 2 2 2 0 0 1 1 2 3]\n",
            "  [1 2 1 1 1 3 1 3 3 3]\n",
            "  [1 0 2 2 0 2 2 1 2 3]]] \n",
            "\n",
            " and the dimensions of the concatenated array 3 are: \n",
            " (3, 4, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R78VfoIjVbrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359e9e37-dacd-423f-a0e6-5f512d5dd200"
      },
      "source": [
        "# Concatenating Torch Tensors\r\n",
        "\r\n",
        "tensor1 = torch.rand(size=(3, 4, 5))\r\n",
        "print(\"Tensor 1 is \\n\", tensor1, \" with dimensions \", tensor1.shape, \"\\n\")\r\n",
        "\r\n",
        "tensor2 = torch.rand(size=(3, 4, 5))\r\n",
        "print(\"Tensor 2 is \\n\", tensor2, \" with dimensions \", tensor2.shape, \"\\n\")\r\n",
        "\r\n",
        "concatenated_tensor1 = torch.cat([tensor1, tensor2],dim=0)\r\n",
        "print(\"Concatenated tensor 1 is \\n\", concatenated_tensor1, \"\\n\\n\", \"and the dimensions of the concatenated tensor 1 are: \\n\", concatenated_tensor1.shape)\r\n",
        "\r\n",
        "concatenated_tensor2 = torch.cat([tensor1, tensor2],dim=1)\r\n",
        "print(\"Concatenated tensor 2 is \\n\", concatenated_tensor2, \"\\n\\n\", \"and the dimensions of the concatenated tensor 2 are: \\n\", concatenated_tensor2.shape)\r\n",
        "\r\n",
        "concatenated_tensor3 = torch.cat([tensor1, tensor2],dim=2)\r\n",
        "print(\"Concatenated tensor 3 is \\n\", concatenated_tensor3, \"\\n\\n\", \"and the dimensions of the concatenated tensor 3 are: \\n\", concatenated_tensor3.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor 1 is \n",
            " tensor([[[0.6012, 0.8179, 0.9736, 0.8175, 0.9747],\n",
            "         [0.4638, 0.0508, 0.2630, 0.8405, 0.4968],\n",
            "         [0.2515, 0.1168, 0.0321, 0.0780, 0.3986],\n",
            "         [0.7742, 0.7703, 0.0178, 0.8119, 0.1087]],\n",
            "\n",
            "        [[0.3943, 0.2973, 0.4037, 0.4018, 0.0513],\n",
            "         [0.0683, 0.4218, 0.5065, 0.2729, 0.6883],\n",
            "         [0.0500, 0.4663, 0.9397, 0.2961, 0.9515],\n",
            "         [0.6811, 0.0488, 0.8163, 0.4423, 0.2768]],\n",
            "\n",
            "        [[0.8998, 0.0960, 0.5537, 0.3953, 0.8571],\n",
            "         [0.6396, 0.7403, 0.6766, 0.3798, 0.3948],\n",
            "         [0.0880, 0.7709, 0.8970, 0.8421, 0.1473],\n",
            "         [0.5223, 0.1475, 0.2248, 0.2086, 0.6709]]])  with dimensions  torch.Size([3, 4, 5]) \n",
            "\n",
            "Tensor 2 is \n",
            " tensor([[[0.2020, 0.4891, 0.5210, 0.8223, 0.1220],\n",
            "         [0.1567, 0.2097, 0.8500, 0.3203, 0.9217],\n",
            "         [0.6808, 0.5633, 0.4963, 0.4012, 0.5627],\n",
            "         [0.3858, 0.4965, 0.5638, 0.1089, 0.2379]],\n",
            "\n",
            "        [[0.9037, 0.0942, 0.4641, 0.9946, 0.6806],\n",
            "         [0.5142, 0.0667, 0.7477, 0.1439, 0.3581],\n",
            "         [0.3322, 0.4260, 0.5055, 0.9124, 0.5624],\n",
            "         [0.9478, 0.8059, 0.1839, 0.7243, 0.1466]],\n",
            "\n",
            "        [[0.2881, 0.6471, 0.6651, 0.8751, 0.3390],\n",
            "         [0.5008, 0.7574, 0.0165, 0.8615, 0.0865],\n",
            "         [0.5069, 0.4150, 0.2367, 0.5661, 0.9135],\n",
            "         [0.3538, 0.2032, 0.3151, 0.0044, 0.7257]]])  with dimensions  torch.Size([3, 4, 5]) \n",
            "\n",
            "Concatenated tensor 1 is \n",
            " tensor([[[0.6012, 0.8179, 0.9736, 0.8175, 0.9747],\n",
            "         [0.4638, 0.0508, 0.2630, 0.8405, 0.4968],\n",
            "         [0.2515, 0.1168, 0.0321, 0.0780, 0.3986],\n",
            "         [0.7742, 0.7703, 0.0178, 0.8119, 0.1087]],\n",
            "\n",
            "        [[0.3943, 0.2973, 0.4037, 0.4018, 0.0513],\n",
            "         [0.0683, 0.4218, 0.5065, 0.2729, 0.6883],\n",
            "         [0.0500, 0.4663, 0.9397, 0.2961, 0.9515],\n",
            "         [0.6811, 0.0488, 0.8163, 0.4423, 0.2768]],\n",
            "\n",
            "        [[0.8998, 0.0960, 0.5537, 0.3953, 0.8571],\n",
            "         [0.6396, 0.7403, 0.6766, 0.3798, 0.3948],\n",
            "         [0.0880, 0.7709, 0.8970, 0.8421, 0.1473],\n",
            "         [0.5223, 0.1475, 0.2248, 0.2086, 0.6709]],\n",
            "\n",
            "        [[0.2020, 0.4891, 0.5210, 0.8223, 0.1220],\n",
            "         [0.1567, 0.2097, 0.8500, 0.3203, 0.9217],\n",
            "         [0.6808, 0.5633, 0.4963, 0.4012, 0.5627],\n",
            "         [0.3858, 0.4965, 0.5638, 0.1089, 0.2379]],\n",
            "\n",
            "        [[0.9037, 0.0942, 0.4641, 0.9946, 0.6806],\n",
            "         [0.5142, 0.0667, 0.7477, 0.1439, 0.3581],\n",
            "         [0.3322, 0.4260, 0.5055, 0.9124, 0.5624],\n",
            "         [0.9478, 0.8059, 0.1839, 0.7243, 0.1466]],\n",
            "\n",
            "        [[0.2881, 0.6471, 0.6651, 0.8751, 0.3390],\n",
            "         [0.5008, 0.7574, 0.0165, 0.8615, 0.0865],\n",
            "         [0.5069, 0.4150, 0.2367, 0.5661, 0.9135],\n",
            "         [0.3538, 0.2032, 0.3151, 0.0044, 0.7257]]]) \n",
            "\n",
            " and the dimensions of the concatenated tensor 1 are: \n",
            " torch.Size([6, 4, 5])\n",
            "Concatenated tensor 2 is \n",
            " tensor([[[0.6012, 0.8179, 0.9736, 0.8175, 0.9747],\n",
            "         [0.4638, 0.0508, 0.2630, 0.8405, 0.4968],\n",
            "         [0.2515, 0.1168, 0.0321, 0.0780, 0.3986],\n",
            "         [0.7742, 0.7703, 0.0178, 0.8119, 0.1087],\n",
            "         [0.2020, 0.4891, 0.5210, 0.8223, 0.1220],\n",
            "         [0.1567, 0.2097, 0.8500, 0.3203, 0.9217],\n",
            "         [0.6808, 0.5633, 0.4963, 0.4012, 0.5627],\n",
            "         [0.3858, 0.4965, 0.5638, 0.1089, 0.2379]],\n",
            "\n",
            "        [[0.3943, 0.2973, 0.4037, 0.4018, 0.0513],\n",
            "         [0.0683, 0.4218, 0.5065, 0.2729, 0.6883],\n",
            "         [0.0500, 0.4663, 0.9397, 0.2961, 0.9515],\n",
            "         [0.6811, 0.0488, 0.8163, 0.4423, 0.2768],\n",
            "         [0.9037, 0.0942, 0.4641, 0.9946, 0.6806],\n",
            "         [0.5142, 0.0667, 0.7477, 0.1439, 0.3581],\n",
            "         [0.3322, 0.4260, 0.5055, 0.9124, 0.5624],\n",
            "         [0.9478, 0.8059, 0.1839, 0.7243, 0.1466]],\n",
            "\n",
            "        [[0.8998, 0.0960, 0.5537, 0.3953, 0.8571],\n",
            "         [0.6396, 0.7403, 0.6766, 0.3798, 0.3948],\n",
            "         [0.0880, 0.7709, 0.8970, 0.8421, 0.1473],\n",
            "         [0.5223, 0.1475, 0.2248, 0.2086, 0.6709],\n",
            "         [0.2881, 0.6471, 0.6651, 0.8751, 0.3390],\n",
            "         [0.5008, 0.7574, 0.0165, 0.8615, 0.0865],\n",
            "         [0.5069, 0.4150, 0.2367, 0.5661, 0.9135],\n",
            "         [0.3538, 0.2032, 0.3151, 0.0044, 0.7257]]]) \n",
            "\n",
            " and the dimensions of the concatenated tensor 2 are: \n",
            " torch.Size([3, 8, 5])\n",
            "Concatenated tensor 3 is \n",
            " tensor([[[0.6012, 0.8179, 0.9736, 0.8175, 0.9747, 0.2020, 0.4891, 0.5210,\n",
            "          0.8223, 0.1220],\n",
            "         [0.4638, 0.0508, 0.2630, 0.8405, 0.4968, 0.1567, 0.2097, 0.8500,\n",
            "          0.3203, 0.9217],\n",
            "         [0.2515, 0.1168, 0.0321, 0.0780, 0.3986, 0.6808, 0.5633, 0.4963,\n",
            "          0.4012, 0.5627],\n",
            "         [0.7742, 0.7703, 0.0178, 0.8119, 0.1087, 0.3858, 0.4965, 0.5638,\n",
            "          0.1089, 0.2379]],\n",
            "\n",
            "        [[0.3943, 0.2973, 0.4037, 0.4018, 0.0513, 0.9037, 0.0942, 0.4641,\n",
            "          0.9946, 0.6806],\n",
            "         [0.0683, 0.4218, 0.5065, 0.2729, 0.6883, 0.5142, 0.0667, 0.7477,\n",
            "          0.1439, 0.3581],\n",
            "         [0.0500, 0.4663, 0.9397, 0.2961, 0.9515, 0.3322, 0.4260, 0.5055,\n",
            "          0.9124, 0.5624],\n",
            "         [0.6811, 0.0488, 0.8163, 0.4423, 0.2768, 0.9478, 0.8059, 0.1839,\n",
            "          0.7243, 0.1466]],\n",
            "\n",
            "        [[0.8998, 0.0960, 0.5537, 0.3953, 0.8571, 0.2881, 0.6471, 0.6651,\n",
            "          0.8751, 0.3390],\n",
            "         [0.6396, 0.7403, 0.6766, 0.3798, 0.3948, 0.5008, 0.7574, 0.0165,\n",
            "          0.8615, 0.0865],\n",
            "         [0.0880, 0.7709, 0.8970, 0.8421, 0.1473, 0.5069, 0.4150, 0.2367,\n",
            "          0.5661, 0.9135],\n",
            "         [0.5223, 0.1475, 0.2248, 0.2086, 0.6709, 0.3538, 0.2032, 0.3151,\n",
            "          0.0044, 0.7257]]]) \n",
            "\n",
            " and the dimensions of the concatenated tensor 3 are: \n",
            " torch.Size([3, 4, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JVV79BCXhPk"
      },
      "source": [
        "### 5b. Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNY9XaT_Xmtr"
      },
      "source": [
        "The stack operation joins a sequence of arrays/tensors along a *new* axis. The axis parameter specifies the index of the new axis in the dimensions of the result. For example, if axis=0 it will be the first dimension and if axis=-1 it will be the last dimension. All arrays/tensors need to be of the same size.  The stacked array/tensor has one more dimension than the input arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_4Zsx3pSdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deefb812-c8c9-4634-f00b-32c8c1d1db56"
      },
      "source": [
        "# Stacking Numpy Arrays\r\n",
        "\r\n",
        "array1 = np.random.randint(3, size = (3, 4, 5))\r\n",
        "print(\"Array 1 is \\n\", array1, \" with dimensions \", array1.shape, \"\\n\")\r\n",
        "\r\n",
        "array2 = np.random.randint(4, size = (3, 4, 5))\r\n",
        "print(\"Array 2 is \\n\", array2, \" with dimensions \", array2.shape, \"\\n\")\r\n",
        "\r\n",
        "stacked_array1 = np.stack((array1, array2), axis = 0) \r\n",
        "print(\"Stacked array 1 is \\n\", stacked_array1, \"\\n\\n\", \"and the dimensions of the stacked array 1 are: \\n\", stacked_array1.shape)\r\n",
        "\r\n",
        "stacked_array2 = np.stack((array1, array2), axis = 1) \r\n",
        "print(\"Stacked array 2 is \\n\", stacked_array2, \"\\n\\n\", \"and the dimensions of the stacked array 2 are: \\n\", stacked_array2.shape)\r\n",
        "\r\n",
        "stacked_array3 = np.stack((array1, array2), axis = 2) \r\n",
        "print(\"Stacked array 3 is \\n\", stacked_array3, \"\\n\\n\", \"and the dimensions of the stacked array 3 are: \\n\", stacked_array3.shape)\r\n",
        "\r\n",
        "stacked_array4 = np.stack((array1, array2), axis = -1)\r\n",
        "print(\"Stacked array 4 is \\n\", stacked_array4, \"\\n\\n\", \"and the dimensions of the stacked array 4 are: \\n\", stacked_array4.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array 1 is \n",
            " [[[2 0 1 1 1]\n",
            "  [2 1 1 1 2]\n",
            "  [0 1 0 1 1]\n",
            "  [2 0 2 0 2]]\n",
            "\n",
            " [[0 2 0 0 0]\n",
            "  [0 1 2 0 0]\n",
            "  [1 2 1 0 0]\n",
            "  [0 0 0 1 0]]\n",
            "\n",
            " [[2 2 2 0 0]\n",
            "  [2 0 2 2 0]\n",
            "  [1 1 1 0 0]\n",
            "  [1 0 0 1 2]]]  with dimensions  (3, 4, 5) \n",
            "\n",
            "Array 2 is \n",
            " [[[2 0 2 1 3]\n",
            "  [3 3 1 2 1]\n",
            "  [2 3 2 1 2]\n",
            "  [3 3 0 0 2]]\n",
            "\n",
            " [[1 3 1 2 2]\n",
            "  [1 0 2 3 0]\n",
            "  [2 0 3 2 1]\n",
            "  [2 1 0 1 1]]\n",
            "\n",
            " [[2 2 3 0 1]\n",
            "  [0 3 0 0 2]\n",
            "  [0 3 1 0 3]\n",
            "  [2 1 3 0 1]]]  with dimensions  (3, 4, 5) \n",
            "\n",
            "Stacked array 1 is \n",
            " [[[[2 0 1 1 1]\n",
            "   [2 1 1 1 2]\n",
            "   [0 1 0 1 1]\n",
            "   [2 0 2 0 2]]\n",
            "\n",
            "  [[0 2 0 0 0]\n",
            "   [0 1 2 0 0]\n",
            "   [1 2 1 0 0]\n",
            "   [0 0 0 1 0]]\n",
            "\n",
            "  [[2 2 2 0 0]\n",
            "   [2 0 2 2 0]\n",
            "   [1 1 1 0 0]\n",
            "   [1 0 0 1 2]]]\n",
            "\n",
            "\n",
            " [[[2 0 2 1 3]\n",
            "   [3 3 1 2 1]\n",
            "   [2 3 2 1 2]\n",
            "   [3 3 0 0 2]]\n",
            "\n",
            "  [[1 3 1 2 2]\n",
            "   [1 0 2 3 0]\n",
            "   [2 0 3 2 1]\n",
            "   [2 1 0 1 1]]\n",
            "\n",
            "  [[2 2 3 0 1]\n",
            "   [0 3 0 0 2]\n",
            "   [0 3 1 0 3]\n",
            "   [2 1 3 0 1]]]] \n",
            "\n",
            " and the dimensions of the stacked array 1 are: \n",
            " (2, 3, 4, 5)\n",
            "Stacked array 2 is \n",
            " [[[[2 0 1 1 1]\n",
            "   [2 1 1 1 2]\n",
            "   [0 1 0 1 1]\n",
            "   [2 0 2 0 2]]\n",
            "\n",
            "  [[2 0 2 1 3]\n",
            "   [3 3 1 2 1]\n",
            "   [2 3 2 1 2]\n",
            "   [3 3 0 0 2]]]\n",
            "\n",
            "\n",
            " [[[0 2 0 0 0]\n",
            "   [0 1 2 0 0]\n",
            "   [1 2 1 0 0]\n",
            "   [0 0 0 1 0]]\n",
            "\n",
            "  [[1 3 1 2 2]\n",
            "   [1 0 2 3 0]\n",
            "   [2 0 3 2 1]\n",
            "   [2 1 0 1 1]]]\n",
            "\n",
            "\n",
            " [[[2 2 2 0 0]\n",
            "   [2 0 2 2 0]\n",
            "   [1 1 1 0 0]\n",
            "   [1 0 0 1 2]]\n",
            "\n",
            "  [[2 2 3 0 1]\n",
            "   [0 3 0 0 2]\n",
            "   [0 3 1 0 3]\n",
            "   [2 1 3 0 1]]]] \n",
            "\n",
            " and the dimensions of the stacked array 2 are: \n",
            " (3, 2, 4, 5)\n",
            "Stacked array 3 is \n",
            " [[[[2 0 1 1 1]\n",
            "   [2 0 2 1 3]]\n",
            "\n",
            "  [[2 1 1 1 2]\n",
            "   [3 3 1 2 1]]\n",
            "\n",
            "  [[0 1 0 1 1]\n",
            "   [2 3 2 1 2]]\n",
            "\n",
            "  [[2 0 2 0 2]\n",
            "   [3 3 0 0 2]]]\n",
            "\n",
            "\n",
            " [[[0 2 0 0 0]\n",
            "   [1 3 1 2 2]]\n",
            "\n",
            "  [[0 1 2 0 0]\n",
            "   [1 0 2 3 0]]\n",
            "\n",
            "  [[1 2 1 0 0]\n",
            "   [2 0 3 2 1]]\n",
            "\n",
            "  [[0 0 0 1 0]\n",
            "   [2 1 0 1 1]]]\n",
            "\n",
            "\n",
            " [[[2 2 2 0 0]\n",
            "   [2 2 3 0 1]]\n",
            "\n",
            "  [[2 0 2 2 0]\n",
            "   [0 3 0 0 2]]\n",
            "\n",
            "  [[1 1 1 0 0]\n",
            "   [0 3 1 0 3]]\n",
            "\n",
            "  [[1 0 0 1 2]\n",
            "   [2 1 3 0 1]]]] \n",
            "\n",
            " and the dimensions of the stacked array 3 are: \n",
            " (3, 4, 2, 5)\n",
            "Stacked array 4 is \n",
            " [[[[2 2]\n",
            "   [0 0]\n",
            "   [1 2]\n",
            "   [1 1]\n",
            "   [1 3]]\n",
            "\n",
            "  [[2 3]\n",
            "   [1 3]\n",
            "   [1 1]\n",
            "   [1 2]\n",
            "   [2 1]]\n",
            "\n",
            "  [[0 2]\n",
            "   [1 3]\n",
            "   [0 2]\n",
            "   [1 1]\n",
            "   [1 2]]\n",
            "\n",
            "  [[2 3]\n",
            "   [0 3]\n",
            "   [2 0]\n",
            "   [0 0]\n",
            "   [2 2]]]\n",
            "\n",
            "\n",
            " [[[0 1]\n",
            "   [2 3]\n",
            "   [0 1]\n",
            "   [0 2]\n",
            "   [0 2]]\n",
            "\n",
            "  [[0 1]\n",
            "   [1 0]\n",
            "   [2 2]\n",
            "   [0 3]\n",
            "   [0 0]]\n",
            "\n",
            "  [[1 2]\n",
            "   [2 0]\n",
            "   [1 3]\n",
            "   [0 2]\n",
            "   [0 1]]\n",
            "\n",
            "  [[0 2]\n",
            "   [0 1]\n",
            "   [0 0]\n",
            "   [1 1]\n",
            "   [0 1]]]\n",
            "\n",
            "\n",
            " [[[2 2]\n",
            "   [2 2]\n",
            "   [2 3]\n",
            "   [0 0]\n",
            "   [0 1]]\n",
            "\n",
            "  [[2 0]\n",
            "   [0 3]\n",
            "   [2 0]\n",
            "   [2 0]\n",
            "   [0 2]]\n",
            "\n",
            "  [[1 0]\n",
            "   [1 3]\n",
            "   [1 1]\n",
            "   [0 0]\n",
            "   [0 3]]\n",
            "\n",
            "  [[1 2]\n",
            "   [0 1]\n",
            "   [0 3]\n",
            "   [1 0]\n",
            "   [2 1]]]] \n",
            "\n",
            " and the dimensions of the stacked array 4 are: \n",
            " (3, 4, 5, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkK1qku6qWPI",
        "outputId": "cbe19f51-6841-46be-a34f-30a4ecb8e4a5"
      },
      "source": [
        "# Stacking Torch Tensors\r\n",
        "\r\n",
        "tensor1 = torch.rand(size=(3, 4, 5))\r\n",
        "print(\"Tensor 1 is \\n\", tensor1, \" with dimensions \", tensor1.shape, \"\\n\")\r\n",
        "\r\n",
        "tensor2 = torch.rand(size=(3, 4, 5))\r\n",
        "print(\"Tensor 2 is \\n\", tensor2, \" with dimensions \", tensor2.shape, \"\\n\")\r\n",
        "\r\n",
        "stacked_tensor1 = torch.stack([tensor1, tensor2],dim=0)\r\n",
        "print(\"Stacked tensor 1 is \\n\", stacked_tensor1, \"\\n\\n\", \"and the dimensions of the stacked tensor 1 are: \\n\", stacked_tensor1.shape)\r\n",
        "\r\n",
        "stacked_tensor2 = torch.stack([tensor1, tensor2],dim=1)\r\n",
        "print(\"Stacked tensor 2 is \\n\", stacked_tensor2, \"\\n\\n\", \"and the dimensions of the stacked tensor 2 are: \\n\", stacked_tensor2.shape)\r\n",
        "\r\n",
        "stacked_tensor3 = torch.stack([tensor1, tensor2],dim=2)\r\n",
        "print(\"Stacked tensor 3 is \\n\", stacked_tensor3, \"\\n\\n\", \"and the dimensions of the stacked tensor 3 are: \\n\", stacked_tensor3.shape)\r\n",
        "\r\n",
        "stacked_tensor4 = torch.stack([tensor1, tensor2],dim=-1)\r\n",
        "print(\"Stacked tensor 4 is \\n\", stacked_tensor4, \"\\n\\n\", \"and the dimensions of the stacked tensor 4 are: \\n\", stacked_tensor4.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor 1 is \n",
            " tensor([[[0.2599, 0.1663, 0.2119, 0.7875, 0.7648],\n",
            "         [0.8838, 0.6814, 0.3330, 0.3603, 0.6477],\n",
            "         [0.9110, 0.6359, 0.2634, 0.2650, 0.0273],\n",
            "         [0.6080, 0.2194, 0.0542, 0.9384, 0.1753]],\n",
            "\n",
            "        [[0.4431, 0.6432, 0.5159, 0.1636, 0.0958],\n",
            "         [0.8985, 0.5814, 0.9148, 0.3324, 0.6473],\n",
            "         [0.3857, 0.4778, 0.1955, 0.6691, 0.6581],\n",
            "         [0.4897, 0.3875, 0.1918, 0.8458, 0.1278]],\n",
            "\n",
            "        [[0.7048, 0.3319, 0.2588, 0.5898, 0.2403],\n",
            "         [0.6152, 0.5982, 0.1288, 0.5832, 0.7130],\n",
            "         [0.6979, 0.4371, 0.0901, 0.4229, 0.6737],\n",
            "         [0.3176, 0.6898, 0.8330, 0.2389, 0.5049]]])  with dimensions  torch.Size([3, 4, 5]) \n",
            "\n",
            "Tensor 2 is \n",
            " tensor([[[0.7067, 0.5392, 0.5418, 0.5624, 0.1069],\n",
            "         [0.5393, 0.8462, 0.9506, 0.7939, 0.5670],\n",
            "         [0.7335, 0.2568, 0.0857, 0.0700, 0.9988],\n",
            "         [0.8174, 0.1544, 0.6956, 0.8776, 0.9998]],\n",
            "\n",
            "        [[0.9372, 0.8874, 0.3854, 0.3245, 0.9105],\n",
            "         [0.7802, 0.1991, 0.9495, 0.7416, 0.7726],\n",
            "         [0.1866, 0.6434, 0.3247, 0.8907, 0.4100],\n",
            "         [0.6947, 0.5888, 0.7127, 0.3301, 0.7438]],\n",
            "\n",
            "        [[0.1508, 0.6129, 0.1617, 0.0067, 0.0985],\n",
            "         [0.8947, 0.7705, 0.9691, 0.9006, 0.0535],\n",
            "         [0.1588, 0.4192, 0.1753, 0.8472, 0.1220],\n",
            "         [0.2560, 0.0170, 0.2161, 0.9112, 0.9094]]])  with dimensions  torch.Size([3, 4, 5]) \n",
            "\n",
            "Stacked tensor 1 is \n",
            " tensor([[[[0.2599, 0.1663, 0.2119, 0.7875, 0.7648],\n",
            "          [0.8838, 0.6814, 0.3330, 0.3603, 0.6477],\n",
            "          [0.9110, 0.6359, 0.2634, 0.2650, 0.0273],\n",
            "          [0.6080, 0.2194, 0.0542, 0.9384, 0.1753]],\n",
            "\n",
            "         [[0.4431, 0.6432, 0.5159, 0.1636, 0.0958],\n",
            "          [0.8985, 0.5814, 0.9148, 0.3324, 0.6473],\n",
            "          [0.3857, 0.4778, 0.1955, 0.6691, 0.6581],\n",
            "          [0.4897, 0.3875, 0.1918, 0.8458, 0.1278]],\n",
            "\n",
            "         [[0.7048, 0.3319, 0.2588, 0.5898, 0.2403],\n",
            "          [0.6152, 0.5982, 0.1288, 0.5832, 0.7130],\n",
            "          [0.6979, 0.4371, 0.0901, 0.4229, 0.6737],\n",
            "          [0.3176, 0.6898, 0.8330, 0.2389, 0.5049]]],\n",
            "\n",
            "\n",
            "        [[[0.7067, 0.5392, 0.5418, 0.5624, 0.1069],\n",
            "          [0.5393, 0.8462, 0.9506, 0.7939, 0.5670],\n",
            "          [0.7335, 0.2568, 0.0857, 0.0700, 0.9988],\n",
            "          [0.8174, 0.1544, 0.6956, 0.8776, 0.9998]],\n",
            "\n",
            "         [[0.9372, 0.8874, 0.3854, 0.3245, 0.9105],\n",
            "          [0.7802, 0.1991, 0.9495, 0.7416, 0.7726],\n",
            "          [0.1866, 0.6434, 0.3247, 0.8907, 0.4100],\n",
            "          [0.6947, 0.5888, 0.7127, 0.3301, 0.7438]],\n",
            "\n",
            "         [[0.1508, 0.6129, 0.1617, 0.0067, 0.0985],\n",
            "          [0.8947, 0.7705, 0.9691, 0.9006, 0.0535],\n",
            "          [0.1588, 0.4192, 0.1753, 0.8472, 0.1220],\n",
            "          [0.2560, 0.0170, 0.2161, 0.9112, 0.9094]]]]) \n",
            "\n",
            " and the dimensions of the stacked tensor 1 are: \n",
            " torch.Size([2, 3, 4, 5])\n",
            "Stacked tensor 2 is \n",
            " tensor([[[[0.2599, 0.1663, 0.2119, 0.7875, 0.7648],\n",
            "          [0.8838, 0.6814, 0.3330, 0.3603, 0.6477],\n",
            "          [0.9110, 0.6359, 0.2634, 0.2650, 0.0273],\n",
            "          [0.6080, 0.2194, 0.0542, 0.9384, 0.1753]],\n",
            "\n",
            "         [[0.7067, 0.5392, 0.5418, 0.5624, 0.1069],\n",
            "          [0.5393, 0.8462, 0.9506, 0.7939, 0.5670],\n",
            "          [0.7335, 0.2568, 0.0857, 0.0700, 0.9988],\n",
            "          [0.8174, 0.1544, 0.6956, 0.8776, 0.9998]]],\n",
            "\n",
            "\n",
            "        [[[0.4431, 0.6432, 0.5159, 0.1636, 0.0958],\n",
            "          [0.8985, 0.5814, 0.9148, 0.3324, 0.6473],\n",
            "          [0.3857, 0.4778, 0.1955, 0.6691, 0.6581],\n",
            "          [0.4897, 0.3875, 0.1918, 0.8458, 0.1278]],\n",
            "\n",
            "         [[0.9372, 0.8874, 0.3854, 0.3245, 0.9105],\n",
            "          [0.7802, 0.1991, 0.9495, 0.7416, 0.7726],\n",
            "          [0.1866, 0.6434, 0.3247, 0.8907, 0.4100],\n",
            "          [0.6947, 0.5888, 0.7127, 0.3301, 0.7438]]],\n",
            "\n",
            "\n",
            "        [[[0.7048, 0.3319, 0.2588, 0.5898, 0.2403],\n",
            "          [0.6152, 0.5982, 0.1288, 0.5832, 0.7130],\n",
            "          [0.6979, 0.4371, 0.0901, 0.4229, 0.6737],\n",
            "          [0.3176, 0.6898, 0.8330, 0.2389, 0.5049]],\n",
            "\n",
            "         [[0.1508, 0.6129, 0.1617, 0.0067, 0.0985],\n",
            "          [0.8947, 0.7705, 0.9691, 0.9006, 0.0535],\n",
            "          [0.1588, 0.4192, 0.1753, 0.8472, 0.1220],\n",
            "          [0.2560, 0.0170, 0.2161, 0.9112, 0.9094]]]]) \n",
            "\n",
            " and the dimensions of the stacked tensor 2 are: \n",
            " torch.Size([3, 2, 4, 5])\n",
            "Stacked tensor 3 is \n",
            " tensor([[[[0.2599, 0.1663, 0.2119, 0.7875, 0.7648],\n",
            "          [0.7067, 0.5392, 0.5418, 0.5624, 0.1069]],\n",
            "\n",
            "         [[0.8838, 0.6814, 0.3330, 0.3603, 0.6477],\n",
            "          [0.5393, 0.8462, 0.9506, 0.7939, 0.5670]],\n",
            "\n",
            "         [[0.9110, 0.6359, 0.2634, 0.2650, 0.0273],\n",
            "          [0.7335, 0.2568, 0.0857, 0.0700, 0.9988]],\n",
            "\n",
            "         [[0.6080, 0.2194, 0.0542, 0.9384, 0.1753],\n",
            "          [0.8174, 0.1544, 0.6956, 0.8776, 0.9998]]],\n",
            "\n",
            "\n",
            "        [[[0.4431, 0.6432, 0.5159, 0.1636, 0.0958],\n",
            "          [0.9372, 0.8874, 0.3854, 0.3245, 0.9105]],\n",
            "\n",
            "         [[0.8985, 0.5814, 0.9148, 0.3324, 0.6473],\n",
            "          [0.7802, 0.1991, 0.9495, 0.7416, 0.7726]],\n",
            "\n",
            "         [[0.3857, 0.4778, 0.1955, 0.6691, 0.6581],\n",
            "          [0.1866, 0.6434, 0.3247, 0.8907, 0.4100]],\n",
            "\n",
            "         [[0.4897, 0.3875, 0.1918, 0.8458, 0.1278],\n",
            "          [0.6947, 0.5888, 0.7127, 0.3301, 0.7438]]],\n",
            "\n",
            "\n",
            "        [[[0.7048, 0.3319, 0.2588, 0.5898, 0.2403],\n",
            "          [0.1508, 0.6129, 0.1617, 0.0067, 0.0985]],\n",
            "\n",
            "         [[0.6152, 0.5982, 0.1288, 0.5832, 0.7130],\n",
            "          [0.8947, 0.7705, 0.9691, 0.9006, 0.0535]],\n",
            "\n",
            "         [[0.6979, 0.4371, 0.0901, 0.4229, 0.6737],\n",
            "          [0.1588, 0.4192, 0.1753, 0.8472, 0.1220]],\n",
            "\n",
            "         [[0.3176, 0.6898, 0.8330, 0.2389, 0.5049],\n",
            "          [0.2560, 0.0170, 0.2161, 0.9112, 0.9094]]]]) \n",
            "\n",
            " and the dimensions of the stacked tensor 3 are: \n",
            " torch.Size([3, 4, 2, 5])\n",
            "Stacked tensor 4 is \n",
            " tensor([[[[0.2599, 0.7067],\n",
            "          [0.1663, 0.5392],\n",
            "          [0.2119, 0.5418],\n",
            "          [0.7875, 0.5624],\n",
            "          [0.7648, 0.1069]],\n",
            "\n",
            "         [[0.8838, 0.5393],\n",
            "          [0.6814, 0.8462],\n",
            "          [0.3330, 0.9506],\n",
            "          [0.3603, 0.7939],\n",
            "          [0.6477, 0.5670]],\n",
            "\n",
            "         [[0.9110, 0.7335],\n",
            "          [0.6359, 0.2568],\n",
            "          [0.2634, 0.0857],\n",
            "          [0.2650, 0.0700],\n",
            "          [0.0273, 0.9988]],\n",
            "\n",
            "         [[0.6080, 0.8174],\n",
            "          [0.2194, 0.1544],\n",
            "          [0.0542, 0.6956],\n",
            "          [0.9384, 0.8776],\n",
            "          [0.1753, 0.9998]]],\n",
            "\n",
            "\n",
            "        [[[0.4431, 0.9372],\n",
            "          [0.6432, 0.8874],\n",
            "          [0.5159, 0.3854],\n",
            "          [0.1636, 0.3245],\n",
            "          [0.0958, 0.9105]],\n",
            "\n",
            "         [[0.8985, 0.7802],\n",
            "          [0.5814, 0.1991],\n",
            "          [0.9148, 0.9495],\n",
            "          [0.3324, 0.7416],\n",
            "          [0.6473, 0.7726]],\n",
            "\n",
            "         [[0.3857, 0.1866],\n",
            "          [0.4778, 0.6434],\n",
            "          [0.1955, 0.3247],\n",
            "          [0.6691, 0.8907],\n",
            "          [0.6581, 0.4100]],\n",
            "\n",
            "         [[0.4897, 0.6947],\n",
            "          [0.3875, 0.5888],\n",
            "          [0.1918, 0.7127],\n",
            "          [0.8458, 0.3301],\n",
            "          [0.1278, 0.7438]]],\n",
            "\n",
            "\n",
            "        [[[0.7048, 0.1508],\n",
            "          [0.3319, 0.6129],\n",
            "          [0.2588, 0.1617],\n",
            "          [0.5898, 0.0067],\n",
            "          [0.2403, 0.0985]],\n",
            "\n",
            "         [[0.6152, 0.8947],\n",
            "          [0.5982, 0.7705],\n",
            "          [0.1288, 0.9691],\n",
            "          [0.5832, 0.9006],\n",
            "          [0.7130, 0.0535]],\n",
            "\n",
            "         [[0.6979, 0.1588],\n",
            "          [0.4371, 0.4192],\n",
            "          [0.0901, 0.1753],\n",
            "          [0.4229, 0.8472],\n",
            "          [0.6737, 0.1220]],\n",
            "\n",
            "         [[0.3176, 0.2560],\n",
            "          [0.6898, 0.0170],\n",
            "          [0.8330, 0.2161],\n",
            "          [0.2389, 0.9112],\n",
            "          [0.5049, 0.9094]]]]) \n",
            "\n",
            " and the dimensions of the stacked tensor 4 are: \n",
            " torch.Size([3, 4, 5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QvL3azFrLdY"
      },
      "source": [
        "### 5c. Repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6egBvLorPJy"
      },
      "source": [
        "The repeat operation repeats elements of an array. The number of repetitions for each element is broadcasted to fit the shape of the given axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqXsl6LNxRBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7f61dd-0fd3-489a-eb4a-68c9cab1cc1e"
      },
      "source": [
        "# Repeat in Numpy Arrays\r\n",
        "\r\n",
        "original_array = np.array([[1,2],[3,4]])\r\n",
        "print(\"Array is \\n\", original_array, \" with dimensions \", original_array.shape, \"\\n\")\r\n",
        "\r\n",
        "repeated_array1 = np.repeat(original_array, 2)\r\n",
        "print(\"Repeated array 1 is \\n\", repeated_array1, \"\\n\\n\", \"and the dimensions of the repeated array 1 are: \\n\", repeated_array1.shape)\r\n",
        "\r\n",
        "repeated_array2 = np.repeat(original_array, 3, axis=0)\r\n",
        "print(\"Repeated array 2 is \\n\", repeated_array2, \"\\n\\n\", \"and the dimensions of the repeated array 2 are: \\n\", repeated_array2.shape)\r\n",
        "\r\n",
        "repeated_array3 = np.repeat(original_array, 3, axis=1)\r\n",
        "print(\"Repeated array 3 is \\n\", repeated_array3, \"\\n\\n\", \"and the dimensions of the repeated array 3 are: \\n\", repeated_array3.shape)\r\n",
        "\r\n",
        "repeated_array4 = np.repeat(original_array, [2,3], axis=0)\r\n",
        "print(\"Repeated array 4 is \\n\", repeated_array4, \"\\n\\n\", \"and the dimensions of the repeated array 4 are: \\n\", repeated_array4.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array is \n",
            " [[1 2]\n",
            " [3 4]]  with dimensions  (2, 2) \n",
            "\n",
            "Repeated array 1 is \n",
            " [1 1 2 2 3 3 4 4] \n",
            "\n",
            " and the dimensions of the repeated array 1 are: \n",
            " (8,)\n",
            "Repeated array 2 is \n",
            " [[1 2]\n",
            " [1 2]\n",
            " [1 2]\n",
            " [3 4]\n",
            " [3 4]\n",
            " [3 4]] \n",
            "\n",
            " and the dimensions of the repeated array 2 are: \n",
            " (6, 2)\n",
            "Repeated array 3 is \n",
            " [[1 1 1 2 2 2]\n",
            " [3 3 3 4 4 4]] \n",
            "\n",
            " and the dimensions of the repeated array 3 are: \n",
            " (2, 6)\n",
            "Repeated array 4 is \n",
            " [[1 2]\n",
            " [1 2]\n",
            " [3 4]\n",
            " [3 4]\n",
            " [3 4]] \n",
            "\n",
            " and the dimensions of the repeated array 4 are: \n",
            " (5, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpJ3xiJWDZXL"
      },
      "source": [
        "**NOTE:** In the Torch version of 'repeat', only the number of repeats can be specified, and will be done along each dimension. This can, however, be done using 'repeat_interleave'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O75Mw4-nyL32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0ff19e-eb28-446b-dfbe-85ac217a697d"
      },
      "source": [
        "# Repeat in Torch Tensors\r\n",
        "\r\n",
        "original_tensor = torch.tensor([1,2,3,4])\r\n",
        "print(\"Tensor is \\n\", original_tensor, \" with dimensions \", original_tensor.shape, \"\\n\")\r\n",
        "\r\n",
        "repeated_tensor1 = original_tensor.repeat((0))\r\n",
        "print(\"Repeated tensor 1 is \\n\", repeated_tensor1, \"\\n\\n\", \"and the dimensions of the repeated tensor 1 are: \\n\", repeated_tensor1.shape)\r\n",
        "\r\n",
        "repeated_tensor2 = original_tensor.repeat((2))\r\n",
        "print(\"Repeated tensor 2 is \\n\", repeated_tensor2, \"\\n\\n\", \"and the dimensions of the repeated tensor 2 are: \\n\", repeated_tensor2.shape)\r\n",
        "\r\n",
        "repeated_tensor3 = original_tensor.repeat((2,3))\r\n",
        "print(\"Repeated tensor 3 is \\n\", repeated_tensor3, \"\\n\\n\", \"and the dimensions of the repeated tensor 3 are: \\n\", repeated_tensor3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor is \n",
            " tensor([1, 2, 3, 4])  with dimensions  torch.Size([4]) \n",
            "\n",
            "Repeated tensor 1 is \n",
            " tensor([], dtype=torch.int64) \n",
            "\n",
            " and the dimensions of the repeated tensor 1 are: \n",
            " torch.Size([0])\n",
            "Repeated tensor 2 is \n",
            " tensor([1, 2, 3, 4, 1, 2, 3, 4]) \n",
            "\n",
            " and the dimensions of the repeated tensor 2 are: \n",
            " torch.Size([8])\n",
            "Repeated tensor 3 is \n",
            " tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
            "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]]) \n",
            "\n",
            " and the dimensions of the repeated tensor 3 are: \n",
            " torch.Size([2, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzhnC32aEZKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a05815-d642-4a85-c720-66089d77c62d"
      },
      "source": [
        "# Repeat Interleave in Torch Tensors\r\n",
        "# will be useful for Homework 4 Part 2 - Beam Search\r\n",
        "\r\n",
        "original_tensor = torch.tensor([[1,2],[3,4]])\r\n",
        "print(\"Tensor is \\n\", original_tensor, \" with dimensions \", original_tensor.shape, \"\\n\")\r\n",
        "\r\n",
        "repeated_tensor1 = original_tensor.repeat_interleave(2)\r\n",
        "print(\"Repeated tensor 1 is \\n\", repeated_tensor1, \"\\n\\n\", \"and the dimensions of the repeated tensor 1 are: \\n\", repeated_tensor1.shape)\r\n",
        "\r\n",
        "repeated_tensor2 = original_tensor.repeat_interleave(3, dim=0)\r\n",
        "print(\"Repeated tensor 2 is \\n\", repeated_tensor2, \"\\n\\n\", \"and the dimensions of the repeated tensor 2 are: \\n\", repeated_tensor2.shape)\r\n",
        "\r\n",
        "repeated_tensor3 = original_tensor.repeat_interleave(3, dim=1)\r\n",
        "print(\"Repeated tensor 3 is \\n\", repeated_tensor3, \"\\n\\n\", \"and the dimensions of the repeated tensor 3 are: \\n\", repeated_tensor3.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor is \n",
            " tensor([[1, 2],\n",
            "        [3, 4]])  with dimensions  torch.Size([2, 2]) \n",
            "\n",
            "Repeated tensor 1 is \n",
            " tensor([1, 1, 2, 2, 3, 3, 4, 4]) \n",
            "\n",
            " and the dimensions of the repeated tensor 1 are: \n",
            " torch.Size([8])\n",
            "Repeated tensor 2 is \n",
            " tensor([[1, 2],\n",
            "        [1, 2],\n",
            "        [1, 2],\n",
            "        [3, 4],\n",
            "        [3, 4],\n",
            "        [3, 4]]) \n",
            "\n",
            " and the dimensions of the repeated tensor 2 are: \n",
            " torch.Size([6, 2])\n",
            "Repeated tensor 3 is \n",
            " tensor([[1, 1, 1, 2, 2, 2],\n",
            "        [3, 3, 3, 4, 4, 4]]) \n",
            "\n",
            " and the dimensions of the repeated tensor 3 are: \n",
            " torch.Size([2, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFIWpGznD7hj"
      },
      "source": [
        "### 5d. Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tgueG8LEKbg"
      },
      "source": [
        "Arrays/tensors need to be padded to ensure that computations can be optimized by transfroming the underlying data to become of the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSo_CfNuDyw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be19ee29-c517-45f7-9c58-2655dd9ffdc6"
      },
      "source": [
        "# Padding Numpy Arrays\r\n",
        "\r\n",
        "original_array = np.array([[1,2,3,4],\r\n",
        "                 [1,2,3,4],\r\n",
        "                 [1,2,3,4],\r\n",
        "                 [1,2,3,4]])\r\n",
        "print(\"Array is \\n\", original_array, \" with dimensions \", original_array.shape, \"\\n\")\r\n",
        "\r\n",
        "# Setting the width of padding for each side\r\n",
        "pad_left   = 1\r\n",
        "pad_right  = 2\r\n",
        "pad_top    = 1\r\n",
        "pad_bottom = 2\r\n",
        "\r\n",
        "padded_array1 = np.pad(original_array, pad_width =  ((pad_top, pad_bottom), (pad_left, pad_right)), mode = 'constant' )\r\n",
        "print(\"Padded array 1 is \\n\", padded_array1, \"\\n\\n\", \"and the dimensions of the padded array 1 are: \\n\", padded_array1.shape)\r\n",
        "\r\n",
        "padded_array2 = np.pad(original_array, pad_width =  ((pad_top, pad_bottom), (pad_left, pad_right)), mode = 'edge' )\r\n",
        "print(\"Padded array 2 is \\n\", padded_array2, \"\\n\\n\", \"and the dimensions of the padded array 2 are: \\n\", padded_array2.shape)\r\n",
        "\r\n",
        "padded_array3 = np.pad(original_array, pad_width =  ((pad_top, pad_bottom), (pad_left, pad_right)), mode = 'reflect' )\r\n",
        "print(\"Padded array 3 is \\n\", padded_array3, \"\\n\\n\", \"and the dimensions of the padded array 3 are: \\n\", padded_array3.shape)\r\n",
        "\r\n",
        "padded_array4 = np.pad(original_array, pad_width =  ((pad_top, pad_bottom), (pad_left, pad_right)), mode = 'symmetric' )\r\n",
        "print(\"Padded array 4 is \\n\", padded_array4, \"\\n\\n\", \"and the dimensions of the padded array 4 are: \\n\", padded_array4.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array is \n",
            " [[1 2 3 4]\n",
            " [1 2 3 4]\n",
            " [1 2 3 4]\n",
            " [1 2 3 4]]  with dimensions  (4, 4) \n",
            "\n",
            "Padded array 1 is \n",
            " [[0 0 0 0 0 0 0]\n",
            " [0 1 2 3 4 0 0]\n",
            " [0 1 2 3 4 0 0]\n",
            " [0 1 2 3 4 0 0]\n",
            " [0 1 2 3 4 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]] \n",
            "\n",
            " and the dimensions of the padded array 1 are: \n",
            " (7, 7)\n",
            "Padded array 2 is \n",
            " [[1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]\n",
            " [1 1 2 3 4 4 4]] \n",
            "\n",
            " and the dimensions of the padded array 2 are: \n",
            " (7, 7)\n",
            "Padded array 3 is \n",
            " [[2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]\n",
            " [2 1 2 3 4 3 2]] \n",
            "\n",
            " and the dimensions of the padded array 3 are: \n",
            " (7, 7)\n",
            "Padded array 4 is \n",
            " [[1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]\n",
            " [1 1 2 3 4 4 3]] \n",
            "\n",
            " and the dimensions of the padded array 4 are: \n",
            " (7, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbkTIf3Dnz1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ae185b-6abb-4c56-b376-86f34d2e90d4"
      },
      "source": [
        "# Padding Torch Tensors\n",
        "# NOTE: Requires special package from torch.nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "original_tensor = torch.tensor([[1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4]])\n",
        "print(\"Tensor is \\n\", original_tensor, \" with dimensions \", original_tensor.shape, \"\\n\")\n",
        "\n",
        "# Setting the width of padding for each side\n",
        "pad_left   = 1\n",
        "pad_right  = 2\n",
        "pad_top    = 1\n",
        "pad_bottom = 2\n",
        "\n",
        "padded_tensor1 = F.pad( original_tensor, (pad_left, pad_right, pad_top, pad_bottom), mode = 'constant' ) # ordering of padding widths is different\n",
        "print(\"Padded tensor 1 is \\n\", padded_tensor1, \"\\n\\n\", \"and the dimensions of the padded tensor 1 are: \\n\", padded_tensor1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor is \n",
            " tensor([[1, 2, 3, 4],\n",
            "        [1, 2, 3, 4],\n",
            "        [1, 2, 3, 4],\n",
            "        [1, 2, 3, 4]])  with dimensions  torch.Size([4, 4]) \n",
            "\n",
            "Padded tensor 1 is \n",
            " tensor([[0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 2, 3, 4, 0, 0],\n",
            "        [0, 1, 2, 3, 4, 0, 0],\n",
            "        [0, 1, 2, 3, 4, 0, 0],\n",
            "        [0, 1, 2, 3, 4, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]]) \n",
            "\n",
            " and the dimensions of the padded tensor 1 are: \n",
            " torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU1a6CgxiHwt"
      },
      "source": [
        "## **6. Mathematical Operations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDjcGMajfCZj"
      },
      "source": [
        "In this section we willcover  some of the most commonly used basic mathematical operations\r\n",
        "1. Point-wise/element-wise operations\r\n",
        "1. Redution operations\r\n",
        "1. Comparison operations\r\n",
        "1. Vector/Matrix operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSRSyK-VfHXs"
      },
      "source": [
        "### 6a. Point-wise/Element-wise operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHtcGhNxgQoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878dc884-aae9-4a0c-b727-12bcca94f49f"
      },
      "source": [
        "# Point-wise/element-wise Array operations\r\n",
        "\r\n",
        "original_array1 = np.random.randint(3, size = (3,)) \r\n",
        "print(\"Original Array 1: \\n\", original_array1, \" with dimensions \", original_array1.shape, \"\\n\")\r\n",
        "\r\n",
        "original_array2 = np.random.randint(3, size = (3,)) \r\n",
        "print(\"Original Array 2: \\n\", original_array2, \" with dimensions \", original_array2.shape, \"\\n\")\r\n",
        "\r\n",
        "original_array3 = np.random.randint(3, size = (3, 4)) \r\n",
        "print(\"Original Array 3: \\n\", original_array3, \" with dimensions \", original_array3.shape, \"\\n\")\r\n",
        "\r\n",
        "original_array4 = np.random.randint(3, size = (3, 4)) \r\n",
        "print(\"Original Array 4: \\n\", original_array4, \" with dimensions \", original_array4.shape, \"\\n\")\r\n",
        "\r\n",
        "original_array5 = np.random.randint(3, size = (3, 1)) \r\n",
        "print(\"Original Array 5: \\n\", original_array5, \" with dimensions \", original_array5.shape, \"\\n\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Addition with Scalars\r\n",
        "print(\"Original_Array1 + 10 =\")\r\n",
        "print(original_array1 + 10, \"\\n\")\r\n",
        "\r\n",
        "# Multiplication with Scalars:\r\n",
        "print(\"Original_Array1 * -10 =\")\r\n",
        "print(original_array1 * -10, \"\\n\")\r\n",
        "\r\n",
        "# Elementwise Addition of Arrays\r\n",
        "print(\"Original_Array1 + Original_Array2 =\")\r\n",
        "print(original_array1 + original_array2, \"\\n\")\r\n",
        "\r\n",
        "print(\"Original_Array3 + Original_Array4 =\")\r\n",
        "print(original_array3 + original_array4, \"\\n\")\r\n",
        "\r\n",
        "# Elementwise Multiplication of Arrays aka Hadmard Product\r\n",
        "print(\"Original_Array1 * Original_Array2 =\")\r\n",
        "print(original_array1 * original_array2, \"\\n\") # also equivalent to np.multiply(array1, array2)\r\n",
        "\r\n",
        "print(\"Original_Array3 * Original_Array4 =\")\r\n",
        "print(original_array3 * original_array4, \"\\n\") # also equivalent to np.multiply(array1, array2)\r\n",
        "\r\n",
        "# Absolute value\r\n",
        "print(\"abs (-10 * Original_Array1) =\")\r\n",
        "print(abs(-10*original_array1), \"\\n\")\r\n",
        "\r\n",
        "# Broadcasting b/w arrays of different dimensions\r\n",
        "# Note: When broadting two multi-dimensional tensors, match their corresponding dimensions beginning from the last dimension.\r\n",
        "# All dimensions should either match or one of the arrays should have length 1 in that specific dimension\r\n",
        "\r\n",
        "print(\"Original_Array3 + Original_Array5 = \\n\")\r\n",
        "print(original_array3 + original_array5)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Array 1: \n",
            " [2 0 0]  with dimensions  (3,) \n",
            "\n",
            "Original Array 2: \n",
            " [0 2 1]  with dimensions  (3,) \n",
            "\n",
            "Original Array 3: \n",
            " [[0 0 0 0]\n",
            " [1 2 2 1]\n",
            " [0 1 1 1]]  with dimensions  (3, 4) \n",
            "\n",
            "Original Array 4: \n",
            " [[1 1 1 2]\n",
            " [2 1 1 1]\n",
            " [2 0 0 0]]  with dimensions  (3, 4) \n",
            "\n",
            "Original Array 5: \n",
            " [[1]\n",
            " [0]\n",
            " [1]]  with dimensions  (3, 1) \n",
            "\n",
            "Original_Array1 + 10 =\n",
            "[12 10 10] \n",
            "\n",
            "Original_Array1 * -10 =\n",
            "[-20   0   0] \n",
            "\n",
            "Original_Array1 + Original_Array2 =\n",
            "[2 2 1] \n",
            "\n",
            "Original_Array3 + Original_Array4 =\n",
            "[[1 1 1 2]\n",
            " [3 3 3 2]\n",
            " [2 1 1 1]] \n",
            "\n",
            "Original_Array1 * Original_Array2 =\n",
            "[0 0 0] \n",
            "\n",
            "Original_Array3 * Original_Array4 =\n",
            "[[0 0 0 0]\n",
            " [2 2 2 1]\n",
            " [0 0 0 0]] \n",
            "\n",
            "abs (-10 * Original_Array1) =\n",
            "[20  0  0] \n",
            "\n",
            "Original_Array3 + Original_Array5 = \n",
            "\n",
            "[[1 1 1 1]\n",
            " [1 2 2 1]\n",
            " [1 2 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-b9qd-TiSa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de1005c-46d1-4f2d-f150-27420e0fb62c"
      },
      "source": [
        "# Point-wise/element-wise Tensor operations\n",
        "\n",
        "original_tensor1 = torch.rand(3)\n",
        "print(\"Original Tensor 1: \\n\", original_tensor1, \" with dimensions \", original_tensor1.shape, \"\\n\")\n",
        "\n",
        "original_tensor2 = torch.rand(3)\n",
        "print(\"Original Tensor 2: \\n\", original_tensor1, \" with dimensions \", original_tensor2.shape, \"\\n\")\n",
        "\n",
        "original_tensor3 = torch.rand(size=(3,4))\n",
        "print(\"Original Tensor 3: \\n\", original_tensor1, \" with dimensions \", original_tensor3.shape, \"\\n\")\n",
        "\n",
        "original_tensor4 = torch.rand(size=(3,4))\n",
        "print(\"Original Tensor 4: \\n\", original_tensor1, \" with dimensions \", original_tensor4.shape, \"\\n\")\n",
        "\n",
        "original_tensor5 = torch.rand(size=(3,1))\n",
        "print(\"Original Tensor 5: \\n\", original_tensor5, \" with dimensions \", original_tensor5.shape, \"\\n\")\n",
        "\n",
        "# Addition with Scalars\n",
        "print(\"Original_Tensor1 + 10 = \\n\")\n",
        "print(original_tensor1 + 10)\n",
        "\n",
        "# Multiplication with Scalars:\n",
        "print(\"Original_Tensor1 * -10 = \\n\")\n",
        "print(original_tensor1 * -10)\n",
        "\n",
        "# Elementwise Addition of Tensors\n",
        "print(\"Original_Tensor1 + Original_Tensor2 =\")\n",
        "print(original_tensor1 + original_tensor2, \"\\n\")\n",
        "\n",
        "print(\"Original_Tensor3 + Original_Tensor4 =\")\n",
        "print(original_tensor3 + original_tensor4), \"\\n\"\n",
        "\n",
        "# Elementwise Multiplication of Tensors aka Hadmard Product\n",
        "print(\"Original_Tensor1 * Original_Tensor2 =\")\n",
        "print(original_tensor1 * original_tensor2, \"\\n\")\n",
        "\n",
        "print(\"Original_Tensor3 * Original_Tensor4 =\")\n",
        "print(original_tensor3 * original_tensor4, \"\\n\")\n",
        "\n",
        "# Absolute value\n",
        "print(\"abs (-10 * Original_Tensor1) =\")\n",
        "print(abs(-10*original_tensor1), \"\\n\")\n",
        "\n",
        "# Broadcasting b/w tensors of different dimensions\n",
        "# Note: When broadting two multi-dimensional tensors, match their corresponding dimensions beginning from the last dimension.\n",
        "# All dimensions should either match or one of the tensor should have length 1 in that specific dimension\n",
        "\n",
        "print(\"Original_Tensor3 + Original_Tensor5 =\")\n",
        "print(original_tensor3 + original_tensor5, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Tensor 1: \n",
            " tensor([0.8579, 0.8861, 0.9446])  with dimensions  torch.Size([3]) \n",
            "\n",
            "Original Tensor 2: \n",
            " tensor([0.8579, 0.8861, 0.9446])  with dimensions  torch.Size([3]) \n",
            "\n",
            "Original Tensor 3: \n",
            " tensor([0.8579, 0.8861, 0.9446])  with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Original Tensor 4: \n",
            " tensor([0.8579, 0.8861, 0.9446])  with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Original Tensor 5: \n",
            " tensor([[0.3178],\n",
            "        [0.7811],\n",
            "        [0.2159]])  with dimensions  torch.Size([3, 1]) \n",
            "\n",
            "Original_Tensor1 + 10 = \n",
            "\n",
            "tensor([10.8579, 10.8861, 10.9446])\n",
            "Original_Tensor1 * -10 = \n",
            "\n",
            "tensor([-8.5792, -8.8606, -9.4459])\n",
            "Original_Tensor1 + Original_Tensor2 =\n",
            "tensor([1.2299, 1.6061, 1.8901]) \n",
            "\n",
            "Original_Tensor3 + Original_Tensor4 =\n",
            "tensor([[1.5209, 1.4429, 0.9700, 1.6973],\n",
            "        [1.1447, 1.2771, 0.8214, 1.3401],\n",
            "        [0.9226, 0.3399, 1.0938, 1.7154]])\n",
            "Original_Tensor1 * Original_Tensor2 =\n",
            "tensor([0.3191, 0.6380, 0.8931]) \n",
            "\n",
            "Original_Tensor3 * Original_Tensor4 =\n",
            "tensor([[0.5692, 0.4430, 0.1600, 0.7188],\n",
            "        [0.2664, 0.3975, 0.1471, 0.3652],\n",
            "        [0.1537, 0.0264, 0.1128, 0.7351]]) \n",
            "\n",
            "abs (-10 * Original_Tensor1) =\n",
            "tensor([8.5792, 8.8606, 9.4459]) \n",
            "\n",
            "Original_Tensor3 + Original_Tensor5 =\n",
            "tensor([[0.9832, 1.3176, 1.0771, 1.1286],\n",
            "        [1.1061, 1.5210, 1.3385, 1.1617],\n",
            "        [0.4341, 0.4353, 0.3312, 1.0516]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkTVkzD3i8Cv"
      },
      "source": [
        "### 6b. Reduction Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAc6B3Yhk2Tf"
      },
      "source": [
        "NumPy & Torch support all commonly used mathematical reduction operations such as sum(), mean(), std(), max(), argmax(), unique() etc. These can either be applied on the entire array/tensor or along specific dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifsKzs9k-rK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5314d571-3a2e-422a-e255-6982a2678468"
      },
      "source": [
        "# Numpy Reduction Operations\r\n",
        "\r\n",
        "original_array1 = np.random.randint(3, size = (3))\r\n",
        "original_array2 = np.random.randint(3, size=(3,4))\r\n",
        "\r\n",
        "print('Original array1: \\n', original_array1)\r\n",
        "print('Original array2: \\n', original_array2)\r\n",
        "\r\n",
        "print('Sum of array1 \\n', original_array1.sum(), \"\\n\\n\")\r\n",
        "print('Sum of array2 \\n', original_array2.sum(), \"\\n\\n\")\r\n",
        "\r\n",
        "print('Sum of array2 elements along axis 0 \\n', original_array2.sum(axis=0), \"\\n\\n\")\r\n",
        "print('Sum of array2 elements along axis 1 \\n', original_array2.sum(axis=1), \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array1: \n",
            " [0 2 2]\n",
            "Original array2: \n",
            " [[1 0 0 0]\n",
            " [0 0 2 1]\n",
            " [0 2 0 2]]\n",
            "Sum of array1 \n",
            " 4 \n",
            "\n",
            "\n",
            "Sum of array2 \n",
            " 8 \n",
            "\n",
            "\n",
            "Sum of array2 elements along axis 0 \n",
            " [1 2 2 3] \n",
            "\n",
            "\n",
            "Sum of array2 elements along axis 1 \n",
            " [1 3 4] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD0cbGhInpsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e398403-2932-450b-fa38-6ac76a75e8ec"
      },
      "source": [
        "# Torch Reduction Operations\n",
        "\n",
        "t1 = torch.rand(3)\n",
        "t2 = torch.rand(size=(3,4))\n",
        "\n",
        "original_tensor1 = np.random.randint(3, size = (3))\n",
        "original_tensor2 = np.random.randint(3, size=(3,4))\n",
        "\n",
        "print('Original tensor1: \\n', original_tensor1)\n",
        "print('Original tensor2: \\n', original_tensor2)\n",
        "\n",
        "print('Sum of tensor1 \\n', original_tensor1.sum(), \"\\n\\n\")\n",
        "print('Sum of tensor2 \\n', original_tensor2.sum(), \"\\n\\n\")\n",
        "\n",
        "print('Sum of tensor2 elements along axis 0 \\n', original_tensor2.sum(axis=0), \"\\n\\n\")\n",
        "print('Sum of tensor2 elements along axis 1 \\n', original_tensor2.sum(axis=1), \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tensor1: \n",
            " [1 0 0]\n",
            "Original tensor2: \n",
            " [[2 1 2 2]\n",
            " [1 0 0 2]\n",
            " [1 1 0 0]]\n",
            "Sum of tensor1 \n",
            " 1 \n",
            "\n",
            "\n",
            "Sum of tensor2 \n",
            " 12 \n",
            "\n",
            "\n",
            "Sum of tensor2 elements along axis 0 \n",
            " [4 2 2 4] \n",
            "\n",
            "\n",
            "Sum of tensor2 elements along axis 1 \n",
            " [7 3 2] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdZYMg1NmWja"
      },
      "source": [
        "### 6c. Comparison Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQirKU_FnyCS"
      },
      "source": [
        "Comparison Operations preform comparision on the array/tensors as a whole as well as along particular axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDrVexELsjkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1a1f95-67be-4b04-a9c5-136d484c96bc"
      },
      "source": [
        "# Numpy Comparison Operations\r\n",
        "\r\n",
        "original_array1 = np.random.randint(3, size=(3,4))\r\n",
        "original_array2 = np.random.randint(3, size=(3,4))\r\n",
        "original_array3 = np.random.randint(3, size=(3,4))\r\n",
        "\r\n",
        "print('Original array1: \\n', original_array1)\r\n",
        "print('Original array2: \\n', original_array2)\r\n",
        "print('Original array2: \\n', original_array3, \"\\n\")\r\n",
        "\r\n",
        "# Element-wise Comparison Operations\r\n",
        "print('original_array1 > original_array2')\r\n",
        "print(original_array1 > original_array2, \"\\n\")\r\n",
        "\r\n",
        "print('original_array2 != t3')\r\n",
        "print(original_array2 != original_array3, \"\\n\")\r\n",
        "\r\n",
        "# Combining reduction operations with boolean tensors\r\n",
        "print((original_array1 > original_array2).any(), \"\\n\")\r\n",
        "print((original_array1 > original_array2).all(), \"\\n\")\r\n",
        "print((original_array1 > original_array2).any(axis=0), \"\\n\")\r\n",
        "print((original_array1 > original_array2).any(axis=1), \"\\n\")\r\n",
        "print((original_array2 != original_array3).any(), \"\\n\")\r\n",
        "print((original_array2 != original_array3).all(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array1: \n",
            " [[0 1 0 1]\n",
            " [1 2 0 2]\n",
            " [0 0 0 2]]\n",
            "Original array2: \n",
            " [[1 2 2 0]\n",
            " [1 1 1 1]\n",
            " [0 1 0 0]]\n",
            "Original array2: \n",
            " [[1 2 0 2]\n",
            " [0 1 1 2]\n",
            " [0 1 1 1]] \n",
            "\n",
            "original_array1 > original_array2\n",
            "[[False False False  True]\n",
            " [False  True False  True]\n",
            " [False False False  True]] \n",
            "\n",
            "original_array2 != t3\n",
            "[[False False  True  True]\n",
            " [ True False False  True]\n",
            " [False False  True  True]] \n",
            "\n",
            "True \n",
            "\n",
            "False \n",
            "\n",
            "[False  True False  True] \n",
            "\n",
            "[ True  True  True] \n",
            "\n",
            "True \n",
            "\n",
            "False \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fnfU-VEozZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa35fa1-378a-4ae4-c1c3-454d2cb9c8bc"
      },
      "source": [
        "# Torch Comparison Operations\n",
        "\n",
        "original_tensor1 = torch.rand(size=(3,4))\n",
        "original_tensor2 = torch.rand(size=(3,4))\n",
        "original_tensor3 = torch.rand(size=(3,4))\n",
        "\n",
        "print('Original tensor1: \\n', original_tensor1)\n",
        "print('Original tensor2: \\n', original_tensor2)\n",
        "print('Original tensor3: \\n', original_tensor3, \"\\n\")\n",
        "\n",
        "# Element-wise Comparison Operations\n",
        "print('original_tensor1 > original_tensor2')\n",
        "print(original_tensor1 > original_tensor2, \"\\n\")\n",
        "\n",
        "print('original_tensor2 != t3')\n",
        "print(original_tensor2 != original_tensor3, \"\\n\\n\")\n",
        "\n",
        "# Combining reduction operations with boolean tensors\n",
        "print((original_tensor1 > original_tensor2).any(), \"\\n\")\n",
        "print((original_tensor1 > original_tensor2).all(), \"\\n\")\n",
        "print((original_tensor1 > original_tensor2).any(axis=0), \"\\n\")\n",
        "print((original_tensor1 > original_tensor2).any(axis=1), \"\\n\")\n",
        "print((original_tensor2 != original_tensor3).any(), \"\\n\")\n",
        "print((original_tensor2 != original_tensor3).all(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tensor1: \n",
            " tensor([[0.6079, 0.1074, 0.6594, 0.7684],\n",
            "        [0.5697, 0.1655, 0.1123, 0.3457],\n",
            "        [0.7195, 0.9932, 0.7875, 0.4437]])\n",
            "Original tensor2: \n",
            " tensor([[0.6753, 0.0095, 0.0729, 0.7333],\n",
            "        [0.2168, 0.7405, 0.1470, 0.2523],\n",
            "        [0.0882, 0.7609, 0.4491, 0.8848]])\n",
            "Original tensor3: \n",
            " tensor([[0.8094, 0.7767, 0.5161, 0.3454],\n",
            "        [0.3913, 0.5665, 0.7479, 0.1497],\n",
            "        [0.9196, 0.4456, 0.0810, 0.2295]]) \n",
            "\n",
            "original_tensor1 > original_tensor2\n",
            "tensor([[False,  True,  True,  True],\n",
            "        [ True, False, False,  True],\n",
            "        [ True,  True,  True, False]]) \n",
            "\n",
            "original_tensor2 != t3\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]]) \n",
            "\n",
            "\n",
            "tensor(True) \n",
            "\n",
            "tensor(False) \n",
            "\n",
            "tensor([True, True, True, True]) \n",
            "\n",
            "tensor([True, True, True]) \n",
            "\n",
            "tensor(True) \n",
            "\n",
            "tensor(True) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGq0WuNKuOCf"
      },
      "source": [
        "### 6d. Vector/Matrix Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXmmYTrZvO-d"
      },
      "source": [
        "In this section we will cover some basic matrix and vector operations which will be useful for assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4KOb_DYvyYu"
      },
      "source": [
        "Here is an example of matrix array multiplication between a $3 \\times 1$ matrix array and a $1 \\times 3$ matrix array:\r\n",
        "$$\r\n",
        "\\boldsymbol{u} \\boldsymbol{v}^T=\r\n",
        "\\left(\\begin{array}{cc} \r\n",
        "u_1 \\\\\r\n",
        "u_2 \\\\\r\n",
        "u_3\r\n",
        "\\end{array}\\right)\r\n",
        "\\left(\\begin{array}{cc} \r\n",
        "v_1 & v_2 & v_3\r\n",
        "\\end{array}\\right)\r\n",
        "=\r\n",
        "\\left(\\begin{array}{cc} \r\n",
        "u_1v_1 & u_1v_2 & u_1v_3\\\\\r\n",
        "u_2v_1 & u_2v_2 & u_2v_3\\\\\r\n",
        "u_3v_1 & u_3v_2 & u_3v_3\r\n",
        "\\end{array}\\right)\r\n",
        "$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd-HGMpAxjKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119278ec-99d0-4d69-b1fc-a299fb074686"
      },
      "source": [
        "# Numpy Vector/Matrix operations\r\n",
        "\r\n",
        "# Vector x Vector\r\n",
        "array1 = np.random.randn(3)\r\n",
        "array2 = np.random.randn(3)\r\n",
        "\r\n",
        "print('Array1 \\n', array1)\r\n",
        "print('Array2 \\n', array2)\r\n",
        "\r\n",
        "print('Matmul of the two arrays can be derived by using np.matmul(array1, array2) \\n', np.matmul(array1, array2))\r\n",
        "print(\"Matmul of the two arrays can also be derived by using array1@array2 \\n\", array1@array2)\r\n",
        "print('Dimensions of resulting product: \\n', np.matmul(array1, array2).shape)\r\n",
        "\r\n",
        "# Matrix x Vector\r\n",
        "array3 = np.random.randn(3, 4)\r\n",
        "array4 = np.random.randn(4)\r\n",
        "\r\n",
        "print('Array3 \\n', array3, \"\\n\")\r\n",
        "print('Array4 \\n', array4, \"\\n\")\r\n",
        "\r\n",
        "print('Matmul of a vector and a matrix can be derived by using np.matmul(array3, array4) \\n', np.matmul(array3, array4))\r\n",
        "print('Matmul of a vector and a matrix can also be derived by using array3@array4 \\n', array3@array4)\r\n",
        "print('Dimensions of resulting product: \\n', np.matmul(array3, array4).shape)\r\n",
        "\r\n",
        "# Matrix x Matrix \r\n",
        "\r\n",
        "matrix1 = np.random.randint(4, size = (2, 3))\r\n",
        "matrix2 = np.random.randint(4, size = (3, 2))\r\n",
        "\r\n",
        "print('Matrix1', matrix1, \"\\n\")\r\n",
        "print('Matrix2', matrix2, \"\\n\")\r\n",
        "\r\n",
        "print('Matmul of two matrices can be derived by using np.matmul(matrix1, matrix2) \\n', np.matmul(matrix1, matrix2))\r\n",
        "print('Dimensions of resulting product: \\n', np.matmul(matrix1, matrix2).shape, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array1 \n",
            " [ 0.92525075 -0.90478616  1.84369153]\n",
            "Array2 \n",
            " [ 1.52550724 -1.44553558  0.37716061]\n",
            "Matmul of the two arrays can be derived by using np.matmul(array1, array2) \n",
            " 3.414745128921027\n",
            "Matmul of the two arrays can also be derived by using array1@array2 \n",
            " 3.414745128921027\n",
            "Dimensions of resulting product: \n",
            " ()\n",
            "Array3 \n",
            " [[-0.07055723  0.60415971  0.472149    0.81991729]\n",
            " [ 0.90751962 -0.58582287  0.93755884 -0.25460809]\n",
            " [ 0.97359871  0.20728277  1.09964197  0.93989698]] \n",
            "\n",
            "Array4 \n",
            " [ 6.06389001e-01  1.76084071e-03 -9.90160143e-01  1.87239408e+00] \n",
            "\n",
            "Matmul of a vector and a matrix can be derived by using np.matmul(array3, array4) \n",
            " [ 1.02598387 -0.85578171  1.26178043]\n",
            "Matmul of a vector and a matrix can also be derived by using array3@array4 \n",
            " [ 1.02598387 -0.85578171  1.26178043]\n",
            "Dimensions of resulting product: \n",
            " (3,)\n",
            "Matrix1 [[3 3 1]\n",
            " [2 1 3]] \n",
            "\n",
            "Matrix2 [[1 3]\n",
            " [0 0]\n",
            " [3 1]] \n",
            "\n",
            "Matmul of two matrices can be derived by using np.matmul(matrix1, matrix2) \n",
            " [[ 6 10]\n",
            " [11  9]]\n",
            "Dimensions of resulting product: \n",
            " (2, 2) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wQRCEUzqMGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5548d66b-26d5-4e5c-a541-677d08150581"
      },
      "source": [
        "# Torch Vector/Matrix operations\n",
        "\n",
        "# Vector x Vector\n",
        "tensor1 = torch.randn(3)\n",
        "tensor2 = torch.randn(3)\n",
        "\n",
        "print('Tensor1', tensor1, \"\\n\")\n",
        "print('Tensor2', tensor2, \"\\n\")\n",
        "\n",
        "print('Matmul of the two tensors can be derived by using torch.matmul(tensor1, tensor2) \\n', torch.matmul(tensor1, tensor2))\n",
        "print('Dimensions of resulting product: \\n', torch.matmul(tensor1, tensor2).shape, \"\\n\")\n",
        "\n",
        "# Matrix x Vector\n",
        "tensor3 = torch.randn(3, 4)\n",
        "tensor4 = torch.randn(4)\n",
        "\n",
        "print('Tensor3', tensor3, \"\\n\")\n",
        "print('Tensor4', tensor4, \"\\n\")\n",
        "\n",
        "print('Matmul of the a vector and a matrix can be derived by using torch.matmul(tensor3, tensor4) \\n', torch.matmul(tensor3, tensor4))\n",
        "print('Dimensions of resulting product: \\n', torch.matmul(tensor3, tensor4).shape, \"\\n\")\n",
        "\n",
        "# Matrix x Matrix\n",
        "matrix1 = torch.randn(2, 3)\n",
        "matrix2 = torch.randn(3, 2)\n",
        "\n",
        "print('Matrix1', matrix1, \"\\n\")\n",
        "print('Matrix2', matrix2, \"\\n\")\n",
        "\n",
        "print('Matmul of two matrices can be derived by using torch.matmul(matrix1, matrix2) \\n', torch.matmul(matrix1, matrix2))\n",
        "print('Dimensions of resulting product: \\n', torch.matmul(matrix1, matrix2).shape, \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor1 tensor([2.8880, 1.8429, 0.9809]) \n",
            "\n",
            "Tensor2 tensor([-0.3797, -1.6273,  0.5248]) \n",
            "\n",
            "Matmul of the two tensors can be derived by using torch.matmul(tensor1, tensor2) \n",
            " tensor(-3.5808)\n",
            "Dimensions of resulting product: \n",
            " torch.Size([]) \n",
            "\n",
            "Tensor3 tensor([[ 0.5726,  0.6149, -0.9225, -0.4292],\n",
            "        [-0.0803, -1.1858, -1.5992, -0.7179],\n",
            "        [-1.8873,  2.1141, -1.0237, -0.8127]]) \n",
            "\n",
            "Tensor4 tensor([-1.0407,  1.4890,  0.4576, -0.2535]) \n",
            "\n",
            "Matmul of the a vector and a matrix can be derived by using torch.matmul(tensor3, tensor4) \n",
            " tensor([ 0.0065, -2.2319,  4.8496])\n",
            "Dimensions of resulting product: \n",
            " torch.Size([3]) \n",
            "\n",
            "Matrix1 tensor([[-0.9865,  0.5242, -0.4363],\n",
            "        [-0.0399, -1.2045,  0.0616]]) \n",
            "\n",
            "Matrix2 tensor([[ 0.5556, -0.3703],\n",
            "        [-0.1451, -0.7339],\n",
            "        [-1.0027,  1.2256]]) \n",
            "\n",
            "Matmul of two matrices can be derived by using torch.matmul(matrix1, matrix2) \n",
            " tensor([[-0.1867, -0.5542],\n",
            "        [ 0.0908,  0.9742]])\n",
            "Dimensions of resulting product: \n",
            " torch.Size([2, 2]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of081ocxuTJi"
      },
      "source": [
        "**Dot Product:** aka Inner product (Matrix multiplication relies on dot product to multiply various combinations of rows and columns.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXj0MWdIuV4T"
      },
      "source": [
        "**Tensor Product:** Tensordot (also known as tensor contraction) sums the product of elements from a and b over the indices specified by a_axes and b_axes. The lists a_axes and b_axes specify those pairs of axes along which to contract the tensors.\r\n",
        "\r\n",
        "To understand in depth please checkout: https://stackoverflow.com/questions/41870228/understanding-tensordot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V_Lw4s1ucO2"
      },
      "source": [
        "**Einsum:** Imagine that we have two multi-dimensional arrays, A and B. Now let's suppose we want to... multiply A with B in a particular way to create new array of products; and then maybe sum this new array along particular axes; and then maybe transpose the axes of the new array in a particular order.\r\n",
        "There's a good chance that einsum will help us do this faster and more memory-efficiently that combinations of the NumPy functions like multiply, sum and transpose will allow.\r\n",
        "\r\n",
        "To understand in depth please checkout: https://stackoverflow.com/questions/26089893/understanding-numpys-einsum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv_yFsDJt_Rc",
        "outputId": "ac43a3ed-a296-4772-8ac1-634541759dc0"
      },
      "source": [
        "# Some More Numpy Vector/Matrix operations\r\n",
        "\r\n",
        "matrix1 = np.random.randint(4, size = (2, 3))\r\n",
        "matrix2 = np.random.randint(4, size = (3, 2))\r\n",
        "\r\n",
        "print('Matrix1', matrix1, \"\\n\")\r\n",
        "print('Matrix2', matrix2, \"\\n\")\r\n",
        "\r\n",
        "# Dot Product\r\n",
        "product = matrix1.dot(matrix2)\r\n",
        "\r\n",
        "print('Using DOT: product= \\n\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "print(\"array3@array4 is an equivalent way of dot product \\n\", matrix1@matrix2, '\\n\\nproduct.shape =', (matrix1@matrix2).shape)\r\n",
        "\r\n",
        "# Tensor Dot\r\n",
        "array5 = np.random.randint(9, size=(3))\r\n",
        "array6 = np.random.randint(9, size=(4,4))\r\n",
        "\r\n",
        "print('Array5 \\n', array5, \"\\n\")\r\n",
        "print('Array6 \\n', array6, \"\\n\")\r\n",
        "\r\n",
        "product = np.tensordot(array5, array6, axes=0)\r\n",
        "\r\n",
        "print('Using TENSORDOT: product = A⨂B =\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "\r\n",
        "# Using einsum\r\n",
        "\r\n",
        "product = np.einsum('ik, kj', matrix1, matrix2)\r\n",
        "print('\\n\\nUsing einsum: product= \\n\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "\r\n",
        "    # Note, the above einsum notation is equivalent to the following\r\n",
        "product = np.einsum('ik, kj -> ij', matrix1, matrix2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix1 [[0 2 0]\n",
            " [0 3 3]] \n",
            "\n",
            "Matrix2 [[3 0]\n",
            " [0 3]\n",
            " [1 3]] \n",
            "\n",
            "Using DOT: product= \n",
            "\n",
            " [[ 0  6]\n",
            " [ 3 18]] \n",
            "\n",
            "product.shape = (2, 2)\n",
            "array3@array4 is an equivalent way of dot product \n",
            " [[ 0  6]\n",
            " [ 3 18]] \n",
            "\n",
            "product.shape = (2, 2)\n",
            "Array5 \n",
            " [7 0 3] \n",
            "\n",
            "Array6 \n",
            " [[8 7 7 1]\n",
            " [8 4 7 0]\n",
            " [4 0 6 4]\n",
            " [2 4 6 3]] \n",
            "\n",
            "Using TENSORDOT: product = A⨂B =\n",
            " [[[56 49 49  7]\n",
            "  [56 28 49  0]\n",
            "  [28  0 42 28]\n",
            "  [14 28 42 21]]\n",
            "\n",
            " [[ 0  0  0  0]\n",
            "  [ 0  0  0  0]\n",
            "  [ 0  0  0  0]\n",
            "  [ 0  0  0  0]]\n",
            "\n",
            " [[24 21 21  3]\n",
            "  [24 12 21  0]\n",
            "  [12  0 18 12]\n",
            "  [ 6 12 18  9]]] \n",
            "\n",
            "product.shape = (3, 4, 4)\n",
            "\n",
            "\n",
            "Using einsum: product= \n",
            "\n",
            " [[ 0  6]\n",
            " [ 3 18]] \n",
            "\n",
            "product.shape = (2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bznCy9apuIha",
        "outputId": "87f13f9c-ed04-42c9-84a9-d2e20af24adb"
      },
      "source": [
        "# Some More Torch Vector/Matrix operations\r\n",
        "\r\n",
        "# Dot Product -- only takes in 1D vectors\r\n",
        "\r\n",
        "tensor1 = torch.randn(3)\r\n",
        "tensor2 = torch.randn(3)\r\n",
        "\r\n",
        "print('Tensor1', tensor1, \"\\n\")\r\n",
        "print('Tensor2', tensor2, \"\\n\")\r\n",
        "\r\n",
        "product = torch.dot(tensor1, tensor2)\r\n",
        "\r\n",
        "print('Using DOT: product= \\n\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "\r\n",
        "# Tensor Dot\r\n",
        "\r\n",
        "tensor3 = torch.randn(3)\r\n",
        "tensor4 = torch.randn(3,4)\r\n",
        "\r\n",
        "print('tensor3 \\n', array5, \"\\n\")\r\n",
        "print('tensor4 \\n', array6, \"\\n\")\r\n",
        "\r\n",
        "product = torch.tensordot(tensor3, tensor4, dims=0)\r\n",
        "\r\n",
        "print('Using TENSORDOT: product = A⨂B =\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "\r\n",
        "# Einsum\r\n",
        "\r\n",
        "matrix1 = torch.randn(2, 3)\r\n",
        "matrix2 = torch.randn(3, 2)\r\n",
        "\r\n",
        "print('Matrix1', matrix1, \"\\n\")\r\n",
        "print('Matrix2', matrix2, \"\\n\")\r\n",
        "\r\n",
        "product = torch.einsum('ik, kj', matrix1, matrix2)\r\n",
        "print('\\n\\nUsing einsum: product= \\n\\n', product, '\\n\\nproduct.shape =', product.shape)\r\n",
        "\r\n",
        "    # Note, the above einsum notation is equivalent to the following\r\n",
        "product = torch.einsum('ik, kj -> ij', matrix1, matrix2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor1 tensor([-0.8864, -0.2119, -2.5407]) \n",
            "\n",
            "Tensor2 tensor([0.4786, 0.9196, 2.3265]) \n",
            "\n",
            "Using DOT: product= \n",
            "\n",
            " tensor(-6.5299) \n",
            "\n",
            "product.shape = torch.Size([])\n",
            "tensor3 \n",
            " [7 0 3] \n",
            "\n",
            "tensor4 \n",
            " [[8 7 7 1]\n",
            " [8 4 7 0]\n",
            " [4 0 6 4]\n",
            " [2 4 6 3]] \n",
            "\n",
            "Using TENSORDOT: product = A⨂B =\n",
            " tensor([[[ 0.2574,  0.3551,  0.1769,  0.2358],\n",
            "         [-0.0885, -0.5970,  0.0283,  0.2319],\n",
            "         [-0.1933, -0.2503,  0.0059,  0.1332]],\n",
            "\n",
            "        [[ 0.6940,  0.9575,  0.4769,  0.6359],\n",
            "         [-0.2387, -1.6096,  0.0763,  0.6252],\n",
            "         [-0.5212, -0.6749,  0.0158,  0.3592]],\n",
            "\n",
            "        [[ 0.1577,  0.2176,  0.1084,  0.1445],\n",
            "         [-0.0542, -0.3657,  0.0173,  0.1421],\n",
            "         [-0.1184, -0.1533,  0.0036,  0.0816]]]) \n",
            "\n",
            "product.shape = torch.Size([3, 3, 4])\n",
            "Matrix1 tensor([[-0.6703, -0.8116,  0.8578],\n",
            "        [-2.1923, -0.4673, -0.9846]]) \n",
            "\n",
            "Matrix2 tensor([[-0.0349, -0.0076],\n",
            "        [ 0.2696, -0.2484],\n",
            "        [-0.7032, -0.7199]]) \n",
            "\n",
            "\n",
            "\n",
            "Using einsum: product= \n",
            "\n",
            " tensor([[-0.7986, -0.4108],\n",
            "        [ 0.6428,  0.8416]]) \n",
            "\n",
            "product.shape = torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}